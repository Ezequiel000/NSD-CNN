{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k64Z8hXNy-sh"
   },
   "source": [
    "#Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_iftfZn2Ndo",
    "outputId": "027459b3-252a-4ca7-f877-ed9a6d90b882"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "LABLE_FILE = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/ppdata/subj01/behav/responses.tsv'\n",
    "FMRI_DIR = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/GLM-fmri-data/subj01'\n",
    "FMRI_DIR_STND = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/standardized-betas/subj01'\n",
    "TRIAL_PER_SESS = 750\n",
    "POSITIVE_DIRECTORY =  'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/standardized_betas/subj01/isCorrect'\n",
    "NEGATIVE_DIRECTORY =  'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/standardized_betas/subj01/isNotCorrect'\n",
    "# !pip install line_profiler\n",
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get the name of all files in the directory containgn the betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # returns a list of all files in the directory to be standardized\n",
    "def getDirFiles(FMRI_DIR):\n",
    "     files = [f for f in os.listdir(FMRI_DIR) if \n",
    "              os.path.isfile(os.path.join(FMRI_DIR, f)) and\n",
    "              f[-5:] == '.hdf5']\n",
    "     files.sort()                          \n",
    "     return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows each scan session is comprised of 750 scans. Each scan is of size (83, 104, 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = getDirFiles(FMRI_DIR)\n",
    "f = files[0]\n",
    "print(f)\n",
    "f = os.path.join(FMRI_DIR, f)\n",
    "scan1=[]\n",
    "with h5py.File(f, \"r\") as file:\n",
    "    print(file.keys())\n",
    "    print(file['betas'].shape)\n",
    "    scan1 = np.array(file['betas'])\n",
    "print(scan1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scan1.max())\n",
    "print(scan1.min())\n",
    "print(scan1.mean(0)[59,27,63])\n",
    "mean = np.mean(scan1,axis=0)\n",
    "print(mean[59,27,63])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "jtKW9A8gbRq9",
    "outputId": "cc67ec52-5d5f-4259-8c61-49cbc34d27ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering labels...\n",
      "       SUBJECT  SESSION  RUN  TRIAL  73KID  10KID        TIME  ISOLD  \\\n",
      "0            1        1    1      1  46003    626    0.505082      0   \n",
      "1            1        1    1      2  61883   5013    0.505128      0   \n",
      "2            1        1    1      3    829   4850    0.505175      0   \n",
      "3            1        1    1      4  67574   8823    0.505221      0   \n",
      "4            1        1    1      5  16021   9538    0.505267      0   \n",
      "...        ...      ...  ...    ...    ...    ...         ...    ...   \n",
      "29995        1       40   12     58  13774   8984  262.629551      1   \n",
      "29996        1       40   12     59  66768   6026  262.629597      1   \n",
      "29997        1       40   12     60  53168   4841  262.629644      1   \n",
      "29998        1       40   12     61   1944   7323  262.629690      1   \n",
      "29999        1       40   12     62   5034   9972  262.629736      1   \n",
      "\n",
      "       ISCORRECT           RT  CHANGEMIND  MEMORYRECENT  MEMORYFIRST  \\\n",
      "0            1.0   803.529781         0.0           NaN          NaN   \n",
      "1            1.0   972.261383         0.0           NaN          NaN   \n",
      "2            1.0   742.351236         0.0           NaN          NaN   \n",
      "3            1.0   747.518479         0.0           NaN          NaN   \n",
      "4            1.0   547.422774         0.0           NaN          NaN   \n",
      "...          ...          ...         ...           ...          ...   \n",
      "29995        0.0  1275.300175         0.0       20963.0      21540.0   \n",
      "29996        1.0   661.379768         0.0          16.0      17622.0   \n",
      "29997        1.0   786.811781         0.0        9483.0      11912.0   \n",
      "29998        1.0   502.626801         0.0          83.0      12162.0   \n",
      "29999        0.0   883.122362         0.0       28968.0      29798.0   \n",
      "\n",
      "       ISOLDCURRENT  ISCORRECTCURRENT  TOTAL1  TOTAL2  BUTTON  MISSINGDATA  \n",
      "0                 0               1.0       1       0     1.0            0  \n",
      "1                 0               1.0       1       0     1.0            0  \n",
      "2                 0               1.0       1       0     1.0            0  \n",
      "3                 0               1.0       1       0     1.0            0  \n",
      "4                 0               1.0       1       0     1.0            0  \n",
      "...             ...               ...     ...     ...     ...          ...  \n",
      "29995             0               1.0       1       0     1.0            0  \n",
      "29996             1               1.0       0       1     2.0            0  \n",
      "29997             0               0.0       0       1     2.0            0  \n",
      "29998             1               1.0       0       1     2.0            0  \n",
      "29999             0               1.0       1       0     1.0            0  \n",
      "\n",
      "[30000 rows x 19 columns]\n",
      "       SUBJECT  SESSION  RUN  TRIAL  73KID  10KID        TIME  ISOLD  \\\n",
      "45           1        1    1     46  28279   4586    0.507350      1   \n",
      "68           1        1    2      6   3586   4135    0.510578      1   \n",
      "90           1        1    2     28  32626    436    0.511689      1   \n",
      "107          1        1    2     45  33484   5169    0.512569      1   \n",
      "121          1        1    2     59  15762   2757    0.513263      1   \n",
      "...        ...      ...  ...    ...    ...    ...         ...    ...   \n",
      "27745        1       37   12     58  16201   1257  246.729582      1   \n",
      "27746        1       37   12     59  55611   7495  246.729629      1   \n",
      "27747        1       37   12     60  69912   1190  246.729675      1   \n",
      "27748        1       37   12     61  67262   5181  246.729721      1   \n",
      "27749        1       37   12     62  37413   1596  246.729767      1   \n",
      "\n",
      "       ISCORRECT           RT  CHANGEMIND  MEMORYRECENT  MEMORYFIRST  \\\n",
      "45           1.0  1104.699282         0.0          28.0          NaN   \n",
      "68           1.0   782.411240         0.0           3.0          NaN   \n",
      "90           1.0   849.658853         0.0          45.0          NaN   \n",
      "107          1.0   903.947890         0.0          41.0          NaN   \n",
      "121          1.0   934.878815         0.0          15.0          NaN   \n",
      "...          ...          ...         ...           ...          ...   \n",
      "27745        1.0   575.265219         0.0          37.0        167.0   \n",
      "27746        1.0  1664.749701         0.0        3119.0       5135.0   \n",
      "27747        0.0  1775.520753         0.0       23762.0          NaN   \n",
      "27748        1.0   517.624946         0.0         135.0       3469.0   \n",
      "27749        1.0   590.508767         0.0          65.0        160.0   \n",
      "\n",
      "       ISOLDCURRENT  ISCORRECTCURRENT  TOTAL1  TOTAL2  BUTTON  MISSINGDATA  \n",
      "45                1               1.0       0       1     2.0            0  \n",
      "68                1               1.0       0       1     2.0            0  \n",
      "90                1               1.0       0       1     2.0            0  \n",
      "107               1               1.0       0       1     2.0            0  \n",
      "121               1               1.0       0       1     2.0            0  \n",
      "...             ...               ...     ...     ...     ...          ...  \n",
      "27745             1               1.0       0       1     2.0            0  \n",
      "27746             0               0.0       0       1     2.0            0  \n",
      "27747             0               1.0       1       0     1.0            0  \n",
      "27748             1               1.0       0       1     2.0            0  \n",
      "27749             1               1.0       0       1     2.0            0  \n",
      "\n",
      "[17905 rows x 19 columns]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISCORRECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27745</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27746</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27747</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27748</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27749</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17905 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ISCORRECT\n",
       "45           1.0\n",
       "68           1.0\n",
       "90           1.0\n",
       "107          1.0\n",
       "121          1.0\n",
       "...          ...\n",
       "27745        1.0\n",
       "27746        1.0\n",
       "27747        0.0\n",
       "27748        1.0\n",
       "27749        1.0\n",
       "\n",
       "[17905 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('filtering labels...')\n",
    "res = pd.read_csv(LABLE_FILE, sep='\\t')\n",
    "res = pd.DataFrame(res)\n",
    "print(res)\n",
    "res = res.loc[res['SESSION'] <= 37]\n",
    "res = res.loc[res['ISOLD'] == 1]\n",
    "res = res.loc[res['ISCORRECT'] > -1]\n",
    "print(res)\n",
    "res = res.filter(items = ['ISCORRECT'] )\n",
    "res\n",
    "# for index, row in res.iterrows():\n",
    "#     print(index, row['ISCORRECT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HMZklVJzRXa"
   },
   "source": [
    "#Standardize all betas in the directory\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O6lS_DPXzRB6"
   },
   "outputs": [],
   "source": [
    "class StandardizeDirectory:\n",
    "  def __init__(self, loading_dir, dumping_dir, response_file):\n",
    "    self.ld = loading_dir\n",
    "    self.dd = dumping_dir\n",
    "    self.rs = response_file\n",
    "    self.index = 0\n",
    "    self.offset = TRIAL_PER_SESS\n",
    "    self.fmri_files = self.getDirFiles()\n",
    "    self.file_handlers ={}\n",
    "    self.open_files()\n",
    "\n",
    "  def __del__(self):\n",
    "    for value in self.file_handlers.items():\n",
    "      value.close()\n",
    "  # returns a list of all files in the directory to be standardized\n",
    "  def getDirFiles(self):\n",
    "     files = [f for f in os.listdir(self.ld) if \n",
    "              os.path.isfile(os.path.join(self.ld, f)) and\n",
    "              f[-5:] == '.hdf5']\n",
    "     files.sort()                          \n",
    "     return files               \n",
    "\n",
    "  def open_files(self): \n",
    "    for file_name in self.fmri_files:\n",
    "      path = os.path.join(FMRI_DIR, file_name)\n",
    "      self.file_handlers[file_name] = h5py.File(path, 'r')\n",
    "\n",
    "  # Input: path of the responses.tsv file\n",
    "  # Output: dictionary of indexes as keys with a corresponding class lable\n",
    "  # in put the sesh number to filter , pass the session as an argument \n",
    "  def get_labels(self):\n",
    "      print('filtering labels...')\n",
    "      res = pd.read_csv(self.rs, sep='\\t')\n",
    "      res = pd.DataFrame(res)\n",
    "      res = res.loc[res['SESSION'] <= 37]\n",
    "      res = res.loc[res['ISOLD'] == 1]\n",
    "      res = res.loc[res['ISCORRECT'] > -1]\n",
    "      res = res.filter(items = ['ISCORRECT'] )\n",
    "      return res\n",
    "\n",
    "  def dump(self):\n",
    " \n",
    "    responses = self.get_labels()\n",
    "    for session in self.file_handlers:\n",
    "      print('standardizing betas from session '+ session)\n",
    "      sesh = np.array(self.file_handlers[session]['betas'])\n",
    "      print(\"loaded the sesh\")\n",
    "      print('getting z-score' )\n",
    "      mean = sesh.mean(0)\n",
    "      std = sesh.std(0)\n",
    "      std = np.where(std == 0, 1, std)\n",
    "      standardized = (sesh-mean)/std\n",
    "      mean=0\n",
    "      std=0\n",
    "      sesh=0\n",
    "      print('z-score complete' )\n",
    "      positive_betas = np.empty(shape = (0, 83, 104, 81))\n",
    "      negative_betas = np.empty(shape = (0, 83, 104, 81))\n",
    "\n",
    "      for index, row in responses.iterrows(): # this iters through the list of ID which is the index of imaghes from 0-29999\n",
    "        if index >= self.offset:\n",
    "          self.index = self.offset\n",
    "          self.offset += TRIAL_PER_SESS\n",
    "          pos = h5py.File(os.path.join(POSITIVE_DIRECTORY+\"/standardized_\"+session), 'w')\n",
    "          pos.create_dataset('betas',data = positive_betas)\n",
    "          pos.close\n",
    "          neg = h5py.File(os.path.join(NEGATIVE_DIRECTORY+\"/standardized_\"+session), 'w')\n",
    "          neg.create_dataset('betas',data = negative_betas)\n",
    "          neg.close\n",
    "          break\n",
    "        elif row['ISCORRECT'] == 1:\n",
    "          print(\"Expanding  Positive array for sample #\",index )\n",
    "          expanded = np.expand_dims(standardized[(index-self.index)], axis=0)\n",
    "          positive_betas = np.concatenate((positive_betas, expanded), axis=0)\n",
    "          print(\"concatenating finalized sample #\",index )\n",
    "          responses = responses.drop(index)\n",
    "         \n",
    "        elif row['ISCORRECT'] == 0:\n",
    "          print(\"Expanding  Negative array for sample\",index )\n",
    "          expanded = np.expand_dims(standardized[(index-self.index)], axis=0)\n",
    "          negative_betas = np.concatenate((negative_betas, expanded), axis=0)\n",
    "          print(\"concatenating finalized sample #\",index )\n",
    "          responses = responses.drop(index)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TosxhDOOMZjW",
    "outputId": "16001725-9d2d-432c-a268-1667fd4501ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering labels...\n",
      "standardizing betas from session betas_session01.hdf5\n",
      "loaded the sesh\n",
      "getting z-score\n",
      "z-score complete\n",
      "Expanding  Positive array for sample # 45\n",
      "concatenating finalized sample # 45\n",
      "Expanding  Positive array for sample # 68\n",
      "concatenating finalized sample # 68\n",
      "Expanding  Positive array for sample # 90\n",
      "concatenating finalized sample # 90\n",
      "Expanding  Positive array for sample # 107\n",
      "concatenating finalized sample # 107\n",
      "Expanding  Positive array for sample # 121\n",
      "concatenating finalized sample # 121\n",
      "Expanding  Positive array for sample # 123\n",
      "concatenating finalized sample # 123\n",
      "Expanding  Positive array for sample # 148\n",
      "concatenating finalized sample # 148\n",
      "Expanding  Positive array for sample # 153\n",
      "concatenating finalized sample # 153\n",
      "Expanding  Positive array for sample # 154\n",
      "concatenating finalized sample # 154\n",
      "Expanding  Positive array for sample # 172\n",
      "concatenating finalized sample # 172\n",
      "Expanding  Negative array for sample 180\n",
      "concatenating finalized sample # 180\n",
      "Expanding  Positive array for sample # 187\n",
      "concatenating finalized sample # 187\n",
      "Expanding  Positive array for sample # 188\n",
      "concatenating finalized sample # 188\n",
      "Expanding  Positive array for sample # 189\n",
      "concatenating finalized sample # 189\n",
      "Expanding  Negative array for sample 191\n",
      "concatenating finalized sample # 191\n",
      "Expanding  Positive array for sample # 196\n",
      "concatenating finalized sample # 196\n",
      "Expanding  Positive array for sample # 212\n",
      "concatenating finalized sample # 212\n",
      "Expanding  Positive array for sample # 213\n",
      "concatenating finalized sample # 213\n",
      "Expanding  Negative array for sample 219\n",
      "concatenating finalized sample # 219\n",
      "Expanding  Positive array for sample # 222\n",
      "concatenating finalized sample # 222\n",
      "Expanding  Positive array for sample # 224\n",
      "concatenating finalized sample # 224\n",
      "Expanding  Positive array for sample # 226\n",
      "concatenating finalized sample # 226\n",
      "Expanding  Negative array for sample 229\n",
      "concatenating finalized sample # 229\n",
      "Expanding  Positive array for sample # 241\n",
      "concatenating finalized sample # 241\n",
      "Expanding  Positive array for sample # 248\n",
      "concatenating finalized sample # 248\n",
      "Expanding  Negative array for sample 263\n",
      "concatenating finalized sample # 263\n",
      "Expanding  Positive array for sample # 264\n",
      "concatenating finalized sample # 264\n",
      "Expanding  Positive array for sample # 265\n",
      "concatenating finalized sample # 265\n",
      "Expanding  Positive array for sample # 270\n",
      "concatenating finalized sample # 270\n",
      "Expanding  Positive array for sample # 278\n",
      "concatenating finalized sample # 278\n",
      "Expanding  Negative array for sample 280\n",
      "concatenating finalized sample # 280\n",
      "Expanding  Positive array for sample # 282\n",
      "concatenating finalized sample # 282\n",
      "Expanding  Positive array for sample # 283\n",
      "concatenating finalized sample # 283\n",
      "Expanding  Positive array for sample # 285\n",
      "concatenating finalized sample # 285\n",
      "Expanding  Positive array for sample # 287\n",
      "concatenating finalized sample # 287\n",
      "Expanding  Positive array for sample # 288\n",
      "concatenating finalized sample # 288\n",
      "Expanding  Positive array for sample # 294\n",
      "concatenating finalized sample # 294\n",
      "Expanding  Negative array for sample 310\n",
      "concatenating finalized sample # 310\n",
      "Expanding  Positive array for sample # 311\n",
      "concatenating finalized sample # 311\n",
      "Expanding  Negative array for sample 320\n",
      "concatenating finalized sample # 320\n",
      "Expanding  Positive array for sample # 328\n",
      "concatenating finalized sample # 328\n",
      "Expanding  Positive array for sample # 333\n",
      "concatenating finalized sample # 333\n",
      "Expanding  Negative array for sample 342\n",
      "concatenating finalized sample # 342\n",
      "Expanding  Positive array for sample # 352\n",
      "concatenating finalized sample # 352\n",
      "Expanding  Negative array for sample 353\n",
      "concatenating finalized sample # 353\n",
      "Expanding  Positive array for sample # 355\n",
      "concatenating finalized sample # 355\n",
      "Expanding  Positive array for sample # 361\n",
      "concatenating finalized sample # 361\n",
      "Expanding  Positive array for sample # 362\n",
      "concatenating finalized sample # 362\n",
      "Expanding  Positive array for sample # 363\n",
      "concatenating finalized sample # 363\n",
      "Expanding  Positive array for sample # 368\n",
      "concatenating finalized sample # 368\n",
      "Expanding  Positive array for sample # 369\n",
      "concatenating finalized sample # 369\n",
      "Expanding  Positive array for sample # 372\n",
      "concatenating finalized sample # 372\n",
      "Expanding  Positive array for sample # 374\n",
      "concatenating finalized sample # 374\n",
      "Expanding  Positive array for sample # 375\n",
      "concatenating finalized sample # 375\n",
      "Expanding  Negative array for sample 378\n",
      "concatenating finalized sample # 378\n",
      "Expanding  Positive array for sample # 381\n",
      "concatenating finalized sample # 381\n",
      "Expanding  Negative array for sample 383\n",
      "concatenating finalized sample # 383\n",
      "Expanding  Positive array for sample # 386\n",
      "concatenating finalized sample # 386\n",
      "Expanding  Positive array for sample # 387\n",
      "concatenating finalized sample # 387\n",
      "Expanding  Positive array for sample # 388\n",
      "concatenating finalized sample # 388\n",
      "Expanding  Negative array for sample 390\n",
      "concatenating finalized sample # 390\n",
      "Expanding  Positive array for sample # 391\n",
      "concatenating finalized sample # 391\n",
      "Expanding  Positive array for sample # 393\n",
      "concatenating finalized sample # 393\n",
      "Expanding  Positive array for sample # 400\n",
      "concatenating finalized sample # 400\n",
      "Expanding  Positive array for sample # 404\n",
      "concatenating finalized sample # 404\n",
      "Expanding  Positive array for sample # 405\n",
      "concatenating finalized sample # 405\n",
      "Expanding  Positive array for sample # 408\n",
      "concatenating finalized sample # 408\n",
      "Expanding  Positive array for sample # 409\n",
      "concatenating finalized sample # 409\n",
      "Expanding  Positive array for sample # 415\n",
      "concatenating finalized sample # 415\n",
      "Expanding  Positive array for sample # 418\n",
      "concatenating finalized sample # 418\n",
      "Expanding  Negative array for sample 419\n",
      "concatenating finalized sample # 419\n",
      "Expanding  Negative array for sample 420\n",
      "concatenating finalized sample # 420\n",
      "Expanding  Positive array for sample # 423\n",
      "concatenating finalized sample # 423\n",
      "Expanding  Positive array for sample # 426\n",
      "concatenating finalized sample # 426\n",
      "Expanding  Positive array for sample # 427\n",
      "concatenating finalized sample # 427\n",
      "Expanding  Positive array for sample # 432\n",
      "concatenating finalized sample # 432\n",
      "Expanding  Positive array for sample # 437\n",
      "concatenating finalized sample # 437\n",
      "Expanding  Positive array for sample # 439\n",
      "concatenating finalized sample # 439\n",
      "Expanding  Positive array for sample # 445\n",
      "concatenating finalized sample # 445\n",
      "Expanding  Positive array for sample # 447\n",
      "concatenating finalized sample # 447\n",
      "Expanding  Positive array for sample # 449\n",
      "concatenating finalized sample # 449\n",
      "Expanding  Positive array for sample # 451\n",
      "concatenating finalized sample # 451\n",
      "Expanding  Positive array for sample # 453\n",
      "concatenating finalized sample # 453\n",
      "Expanding  Positive array for sample # 456\n",
      "concatenating finalized sample # 456\n",
      "Expanding  Positive array for sample # 457\n",
      "concatenating finalized sample # 457\n",
      "Expanding  Positive array for sample # 459\n",
      "concatenating finalized sample # 459\n",
      "Expanding  Positive array for sample # 462\n",
      "concatenating finalized sample # 462\n",
      "Expanding  Negative array for sample 464\n",
      "concatenating finalized sample # 464\n",
      "Expanding  Positive array for sample # 477\n",
      "concatenating finalized sample # 477\n",
      "Expanding  Positive array for sample # 480\n",
      "concatenating finalized sample # 480\n",
      "Expanding  Positive array for sample # 481\n",
      "concatenating finalized sample # 481\n",
      "Expanding  Positive array for sample # 485\n",
      "concatenating finalized sample # 485\n",
      "Expanding  Negative array for sample 487\n",
      "concatenating finalized sample # 487\n",
      "Expanding  Positive array for sample # 488\n",
      "concatenating finalized sample # 488\n",
      "Expanding  Positive array for sample # 489\n",
      "concatenating finalized sample # 489\n",
      "Expanding  Positive array for sample # 491\n",
      "concatenating finalized sample # 491\n",
      "Expanding  Positive array for sample # 492\n",
      "concatenating finalized sample # 492\n",
      "Expanding  Positive array for sample # 493\n",
      "concatenating finalized sample # 493\n",
      "Expanding  Positive array for sample # 500\n",
      "concatenating finalized sample # 500\n",
      "Expanding  Positive array for sample # 501\n",
      "concatenating finalized sample # 501\n",
      "Expanding  Positive array for sample # 502\n",
      "concatenating finalized sample # 502\n",
      "Expanding  Positive array for sample # 503\n",
      "concatenating finalized sample # 503\n",
      "Expanding  Positive array for sample # 506\n",
      "concatenating finalized sample # 506\n",
      "Expanding  Positive array for sample # 508\n",
      "concatenating finalized sample # 508\n",
      "Expanding  Positive array for sample # 512\n",
      "concatenating finalized sample # 512\n",
      "Expanding  Positive array for sample # 513\n",
      "concatenating finalized sample # 513\n",
      "Expanding  Positive array for sample # 516\n",
      "concatenating finalized sample # 516\n",
      "Expanding  Positive array for sample # 517\n",
      "concatenating finalized sample # 517\n",
      "Expanding  Positive array for sample # 534\n",
      "concatenating finalized sample # 534\n",
      "Expanding  Positive array for sample # 538\n",
      "concatenating finalized sample # 538\n",
      "Expanding  Positive array for sample # 539\n",
      "concatenating finalized sample # 539\n",
      "Expanding  Positive array for sample # 546\n",
      "concatenating finalized sample # 546\n",
      "Expanding  Positive array for sample # 549\n",
      "concatenating finalized sample # 549\n",
      "Expanding  Positive array for sample # 550\n",
      "concatenating finalized sample # 550\n",
      "Expanding  Positive array for sample # 553\n",
      "concatenating finalized sample # 553\n",
      "Expanding  Positive array for sample # 554\n",
      "concatenating finalized sample # 554\n",
      "Expanding  Positive array for sample # 560\n",
      "concatenating finalized sample # 560\n",
      "Expanding  Positive array for sample # 563\n",
      "concatenating finalized sample # 563\n",
      "Expanding  Positive array for sample # 565\n",
      "concatenating finalized sample # 565\n",
      "Expanding  Positive array for sample # 570\n",
      "concatenating finalized sample # 570\n",
      "Expanding  Positive array for sample # 573\n",
      "concatenating finalized sample # 573\n",
      "Expanding  Positive array for sample # 575\n",
      "concatenating finalized sample # 575\n",
      "Expanding  Positive array for sample # 576\n",
      "concatenating finalized sample # 576\n",
      "Expanding  Positive array for sample # 584\n",
      "concatenating finalized sample # 584\n",
      "Expanding  Positive array for sample # 587\n",
      "concatenating finalized sample # 587\n",
      "Expanding  Positive array for sample # 589\n",
      "concatenating finalized sample # 589\n",
      "Expanding  Negative array for sample 593\n",
      "concatenating finalized sample # 593\n",
      "Expanding  Positive array for sample # 598\n",
      "concatenating finalized sample # 598\n",
      "Expanding  Positive array for sample # 599\n",
      "concatenating finalized sample # 599\n",
      "Expanding  Positive array for sample # 608\n",
      "concatenating finalized sample # 608\n",
      "Expanding  Negative array for sample 609\n",
      "concatenating finalized sample # 609\n",
      "Expanding  Positive array for sample # 611\n",
      "concatenating finalized sample # 611\n",
      "Expanding  Positive array for sample # 620\n",
      "concatenating finalized sample # 620\n",
      "Expanding  Positive array for sample # 621\n",
      "concatenating finalized sample # 621\n",
      "Expanding  Positive array for sample # 624\n",
      "concatenating finalized sample # 624\n",
      "Expanding  Positive array for sample # 632\n",
      "concatenating finalized sample # 632\n",
      "Expanding  Positive array for sample # 636\n",
      "concatenating finalized sample # 636\n",
      "Expanding  Positive array for sample # 639\n",
      "concatenating finalized sample # 639\n",
      "Expanding  Positive array for sample # 640\n",
      "concatenating finalized sample # 640\n",
      "Expanding  Negative array for sample 646\n",
      "concatenating finalized sample # 646\n",
      "Expanding  Positive array for sample # 650\n",
      "concatenating finalized sample # 650\n",
      "Expanding  Positive array for sample # 656\n",
      "concatenating finalized sample # 656\n",
      "Expanding  Positive array for sample # 658\n",
      "concatenating finalized sample # 658\n",
      "Expanding  Positive array for sample # 659\n",
      "concatenating finalized sample # 659\n",
      "Expanding  Positive array for sample # 664\n",
      "concatenating finalized sample # 664\n",
      "Expanding  Positive array for sample # 667\n",
      "concatenating finalized sample # 667\n",
      "Expanding  Positive array for sample # 674\n",
      "concatenating finalized sample # 674\n",
      "Expanding  Positive array for sample # 676\n",
      "concatenating finalized sample # 676\n",
      "Expanding  Positive array for sample # 678\n",
      "concatenating finalized sample # 678\n",
      "Expanding  Positive array for sample # 679\n",
      "concatenating finalized sample # 679\n",
      "Expanding  Positive array for sample # 683\n",
      "concatenating finalized sample # 683\n",
      "Expanding  Positive array for sample # 684\n",
      "concatenating finalized sample # 684\n",
      "Expanding  Positive array for sample # 686\n",
      "concatenating finalized sample # 686\n",
      "Expanding  Positive array for sample # 689\n",
      "concatenating finalized sample # 689\n",
      "Expanding  Positive array for sample # 691\n",
      "concatenating finalized sample # 691\n",
      "Expanding  Positive array for sample # 692\n",
      "concatenating finalized sample # 692\n",
      "Expanding  Positive array for sample # 699\n",
      "concatenating finalized sample # 699\n",
      "Expanding  Positive array for sample # 709\n",
      "concatenating finalized sample # 709\n",
      "Expanding  Positive array for sample # 714\n",
      "concatenating finalized sample # 714\n",
      "Expanding  Positive array for sample # 719\n",
      "concatenating finalized sample # 719\n",
      "Expanding  Positive array for sample # 720\n",
      "concatenating finalized sample # 720\n",
      "Expanding  Positive array for sample # 724\n",
      "concatenating finalized sample # 724\n",
      "Expanding  Positive array for sample # 726\n",
      "concatenating finalized sample # 726\n",
      "Expanding  Positive array for sample # 727\n",
      "concatenating finalized sample # 727\n",
      "Expanding  Positive array for sample # 737\n",
      "concatenating finalized sample # 737\n",
      "Expanding  Positive array for sample # 738\n",
      "concatenating finalized sample # 738\n",
      "Expanding  Positive array for sample # 740\n",
      "concatenating finalized sample # 740\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to create file (unable to open file: name = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/standardized_betas/subj01/isCorrect/standardized_betas_session01.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m st \u001b[38;5;241m=\u001b[39m StandardizeDirectory(FMRI_DIR, FMRI_DIR_STND, LABLE_FILE)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[2], line 64\u001b[0m, in \u001b[0;36mStandardizeDirectory.dump\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moffset \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m TRIAL_PER_SESS\n\u001b[1;32m---> 64\u001b[0m pos \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPOSITIVE_DIRECTORY\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/standardized_\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43msession\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mw\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     65\u001b[0m pos\u001b[38;5;241m.\u001b[39mcreate_dataset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m'\u001b[39m,data \u001b[38;5;241m=\u001b[39m positive_betas)\n\u001b[0;32m     66\u001b[0m pos\u001b[38;5;241m.\u001b[39mclose\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\NSD-CNN\\lib\\site-packages\\h5py\\_hl\\files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=557'>558</a>\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=558'>559</a>\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=559'>560</a>\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=560'>561</a>\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=561'>562</a>\u001b[0m                      meta_block_size\u001b[39m=\u001b[39mmeta_block_size,\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=562'>563</a>\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=563'>564</a>\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=564'>565</a>\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=565'>566</a>\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[1;32m--> <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=566'>567</a>\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=568'>569</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=569'>570</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\NSD-CNN\\lib\\site-packages\\h5py\\_hl\\files.py:237\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=234'>235</a>\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mcreate(name, h5f\u001b[39m.\u001b[39mACC_EXCL, fapl\u001b[39m=\u001b[39mfapl, fcpl\u001b[39m=\u001b[39mfcpl)\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=235'>236</a>\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mw\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m--> <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=236'>237</a>\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mcreate(name, h5f\u001b[39m.\u001b[39;49mACC_TRUNC, fapl\u001b[39m=\u001b[39;49mfapl, fcpl\u001b[39m=\u001b[39;49mfcpl)\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=237'>238</a>\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39ma\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=238'>239</a>\u001b[0m     \u001b[39m# Open in append mode (read/write).\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=239'>240</a>\u001b[0m     \u001b[39m# If that fails, create a new file only if it won't clobber an\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=240'>241</a>\u001b[0m     \u001b[39m# existing one (ACC_EXCL)\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/NSD-CNN/lib/site-packages/h5py/_hl/files.py?line=241'>242</a>\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mh5py\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\h5f.pyx:126\u001b[0m, in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to create file (unable to open file: name = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/standardized_betas/subj01/isCorrect/standardized_betas_session01.hdf5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "st = StandardizeDirectory(FMRI_DIR, FMRI_DIR_STND, LABLE_FILE)\n",
    "st.dump()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6H1EipqUJAYS",
    "hdrpCkvYmEIr"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "NSD_CNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0eedda28e726887389b12365826c9a3c7088b0ff5b05732616b72a6f777d840"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
