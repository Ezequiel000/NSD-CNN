{"cells":[{"cell_type":"markdown","metadata":{"id":"QVRocw5UfXeg"},"source":["# Import all libs"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31739,"status":"ok","timestamp":1675840062466,"user":{"displayName":"Ezequiel Hernandez","userId":"10229188064205579760"},"user_tz":480},"id":"ILFerXaqfHAf","outputId":"508ca65b-54f2-4efa-d0a1-4ad0099f6f17"},"outputs":[],"source":["import os\n","import numpy as np\n","import random\n","import tensorflow as tf\n","import h5py\n","from scipy import ndimage\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","\n","FMRI_DIR = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/GLM-fmri-data/subj01'\n","TRIAL_PER_SESS = 750\n","POSITIVE_DIRECTORY =  'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/standardized-betas/subj01/isCorrect/'\n","NEGATIVE_DIRECTORY =  'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/standardized-betas/subj01/isNotCorrect/'\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["2.6.0\n","[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'), PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]\n"]}],"source":["print(tf.__version__)\n","# print(tf.config.list_physical_devices())\n","\n","print(tf.config.list_physical_devices('GPU'))"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":213,"status":"ok","timestamp":1675841272797,"user":{"displayName":"Ezequiel Hernandez","userId":"10229188064205579760"},"user_tz":480},"id":"vuseHkpq9ezd"},"outputs":[],"source":["  # returns a list of all files in the directory\n","def getDirFiles(file_dir):\n","     files = [f for f in os.listdir(file_dir) if \n","              os.path.isfile(os.path.join(file_dir, f))]\n","     files.sort()                          \n","     return files"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":171,"status":"ok","timestamp":1675841172727,"user":{"displayName":"Ezequiel Hernandez","userId":"10229188064205579760"},"user_tz":480},"id":"xZqd_N3U4xv7"},"outputs":[],"source":["positive_paths = [os.path.join(POSITIVE_DIRECTORY, path) for path in getDirFiles(POSITIVE_DIRECTORY)]\n","negative_paths = [os.path.join(NEGATIVE_DIRECTORY, path) for path in getDirFiles(NEGATIVE_DIRECTORY)]"]},{"cell_type":"markdown","metadata":{"id":"q3FzZQPf3MOY"},"source":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"PMbtIw7e_fih"},"outputs":[],"source":["def getSamples(path, num_samples = False):\n","    total_samples = []\n","    samples_size = 0\n","    for data_file in path:\n","        with h5py.File(data_file, \"r\") as f:\n","            samples_size += f['betas'].shape[0]\n","            total_samples.append(np.array(f['betas']))\n","            \n","            if num_samples != False and samples_size > num_samples:\n","                break\n","   \n","    return np.concatenate(total_samples)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["negative_samples = getSamples(negative_paths)"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[],"source":["positive_samples = getSamples(positive_paths, num_samples= len(negative_samples))"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["4491\n","4210\n","5.37569923921784\n","-5.8988419018919345\n"]}],"source":["print(len(positive_samples))\n","print(len(negative_samples))\n","print(positive_samples[10].max())\n","print(positive_samples[10].min())"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of samples in train and validation are 1740 and 6961.\n"]}],"source":["\n","\n","positive_labels = np.array([1 for _ in range(len(positive_samples))])\n","negative_labels = np.array([0 for _ in range(len(negative_samples))])\n","# Split data in the ratio 80-20 for training and validation.\n","split_pos = round(len(positive_labels) *.2)\n","split_neg = round(len(negative_labels) *.2)\n","\n","x_train = np.concatenate((positive_samples[:split_pos], negative_samples[:split_neg]), axis=0)\n","y_train = np.concatenate((positive_labels[:split_pos], negative_labels[:split_neg]), axis=0)\n","\n","x_val = np.concatenate((positive_samples[split_pos:], negative_samples[split_neg:]), axis=0)\n","y_val = np.concatenate((positive_labels[split_pos:], negative_labels[split_neg:]), axis=0)\n","print(\n","    \"Number of samples in train and validation are %d and %d.\"\n","    % (x_train.shape[0], x_val.shape[0])\n",")\n","\n"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["negative_samples = 0\n","positive_samples = 0"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["\n","\n","@tf.function\n","def rotate(volume):\n","    \"\"\"Rotate the volume by a few degrees\"\"\"\n","\n","    def scipy_rotate(volume):\n","        # define some rotation angles\n","        angles = [-20, -10, -5, 5, 10, 20]\n","        # pick angles at random\n","        angle = random.choice(angles)\n","        # rotate volume\n","        volume = ndimage.rotate(volume, angle, reshape=False)\n","        volume[volume < 0] = 0\n","        volume[volume > 1] = 1\n","        return volume\n","\n","    augmented_volume = tf.numpy_function(scipy_rotate, [volume], tf.double)\n","    return augmented_volume\n","\n","\n","def train_preprocessing(volume, label):\n","    \"\"\"Process training data by rotating and adding a channel.\"\"\"\n","    # Rotate volume\n","    volume = rotate(volume)\n","    volume = tf.expand_dims(volume, axis=3)\n","    return volume, label\n","\n","\n","def validation_preprocessing(volume, label):\n","    \"\"\"Process validation data by only adding a channel.\"\"\"\n","    volume = tf.expand_dims(volume, axis=3)\n","    return volume, label"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"ename":"InternalError","evalue":"Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)","Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Define data loaders.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataset\u001b[38;5;241m.\u001b[39mfrom_tensor_slices((x_train, y_train))\n\u001b[1;32m----> 3\u001b[0m validation_loader \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Augment the on the fly during training.\u001b[39;00m\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:685\u001b[0m, in \u001b[0;36mDatasetV2.from_tensor_slices\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=607'>608</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=608'>609</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_tensor_slices\u001b[39m(tensors):\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=609'>610</a>\u001b[0m   \u001b[39m\"\"\"Creates a `Dataset` whose elements are slices of the given tensors.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=610'>611</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=611'>612</a>\u001b[0m \u001b[39m  The given tensors are sliced along their first dimension. This operation\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=682'>683</a>\u001b[0m \u001b[39m    Dataset: A `Dataset`.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=683'>684</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=684'>685</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m TensorSliceDataset(tensors)\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:3844\u001b[0m, in \u001b[0;36mTensorSliceDataset.__init__\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=3841'>3842</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, element):\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=3842'>3843</a>\u001b[0m   \u001b[39m\"\"\"See `Dataset.from_tensor_slices()` for details.\"\"\"\u001b[39;00m\n\u001b[1;32m-> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=3843'>3844</a>\u001b[0m   element \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39;49mnormalize_element(element)\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=3844'>3845</a>\u001b[0m   batched_spec \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mtype_spec_from_value(element)\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/ops/dataset_ops.py?line=3845'>3846</a>\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tensors \u001b[39m=\u001b[39m structure\u001b[39m.\u001b[39mto_batched_tensor_list(batched_spec, element)\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\data\\util\\structure.py:129\u001b[0m, in \u001b[0;36mnormalize_element\u001b[1;34m(element, element_signature)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/util/structure.py?line=125'>126</a>\u001b[0m       \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/util/structure.py?line=126'>127</a>\u001b[0m         dtype \u001b[39m=\u001b[39m \u001b[39mgetattr\u001b[39m(spec, \u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/util/structure.py?line=127'>128</a>\u001b[0m         normalized_components\u001b[39m.\u001b[39mappend(\n\u001b[1;32m--> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/util/structure.py?line=128'>129</a>\u001b[0m             ops\u001b[39m.\u001b[39;49mconvert_to_tensor(t, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcomponent_\u001b[39;49m\u001b[39m%d\u001b[39;49;00m\u001b[39m\"\u001b[39;49m \u001b[39m%\u001b[39;49m i, dtype\u001b[39m=\u001b[39;49mdtype))\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/data/util/structure.py?line=129'>130</a>\u001b[0m \u001b[39mreturn\u001b[39;00m nest\u001b[39m.\u001b[39mpack_sequence_as(pack_as, normalized_components)\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\profiler\\trace.py:163\u001b[0m, in \u001b[0;36mtrace_wrapper.<locals>.inner_wrapper.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/profiler/trace.py?line=160'>161</a>\u001b[0m   \u001b[39mwith\u001b[39;00m Trace(trace_name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mtrace_kwargs):\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/profiler/trace.py?line=161'>162</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/profiler/trace.py?line=162'>163</a>\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py:1566\u001b[0m, in \u001b[0;36mconvert_to_tensor\u001b[1;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/ops.py?line=1560'>1561</a>\u001b[0m       \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mconvert_to_tensor did not convert to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/ops.py?line=1561'>1562</a>\u001b[0m                       \u001b[39m\"\u001b[39m\u001b[39mthe preferred dtype: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m vs \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/ops.py?line=1562'>1563</a>\u001b[0m                       (ret\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mbase_dtype, preferred_dtype\u001b[39m.\u001b[39mbase_dtype))\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/ops.py?line=1564'>1565</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/ops.py?line=1565'>1566</a>\u001b[0m   ret \u001b[39m=\u001b[39m conversion_func(value, dtype\u001b[39m=\u001b[39;49mdtype, name\u001b[39m=\u001b[39;49mname, as_ref\u001b[39m=\u001b[39;49mas_ref)\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/ops.py?line=1567'>1568</a>\u001b[0m \u001b[39mif\u001b[39;00m ret \u001b[39mis\u001b[39;00m \u001b[39mNotImplemented\u001b[39m:\n\u001b[0;32m   <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/ops.py?line=1568'>1569</a>\u001b[0m   \u001b[39mcontinue\u001b[39;00m\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\tensor_conversion_registry.py:52\u001b[0m, in \u001b[0;36m_default_conversion_function\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/tensor_conversion_registry.py?line=49'>50</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_default_conversion_function\u001b[39m(value, dtype, name, as_ref):\n\u001b[0;32m     <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/tensor_conversion_registry.py?line=50'>51</a>\u001b[0m   \u001b[39mdel\u001b[39;00m as_ref  \u001b[39m# Unused.\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/tensor_conversion_registry.py?line=51'>52</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m constant_op\u001b[39m.\u001b[39;49mconstant(value, dtype, name\u001b[39m=\u001b[39;49mname)\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:271\u001b[0m, in \u001b[0;36mconstant\u001b[1;34m(value, dtype, shape, name)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=173'>174</a>\u001b[0m \u001b[39m@tf_export\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mconstant\u001b[39m\u001b[39m\"\u001b[39m, v1\u001b[39m=\u001b[39m[])\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=174'>175</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mconstant\u001b[39m(value, dtype\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, shape\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mConst\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=175'>176</a>\u001b[0m   \u001b[39m\"\"\"Creates a constant tensor from a tensor-like object.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=176'>177</a>\u001b[0m \n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=177'>178</a>\u001b[0m \u001b[39m  Note: All eager `tf.Tensor` values are immutable (in contrast to\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=268'>269</a>\u001b[0m \u001b[39m    ValueError: if called on a symbolic tensor.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=269'>270</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=270'>271</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_impl(value, dtype, shape, name, verify_shape\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=271'>272</a>\u001b[0m                         allow_broadcast\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:283\u001b[0m, in \u001b[0;36m_constant_impl\u001b[1;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=280'>281</a>\u001b[0m     \u001b[39mwith\u001b[39;00m trace\u001b[39m.\u001b[39mTrace(\u001b[39m\"\u001b[39m\u001b[39mtf.constant\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=281'>282</a>\u001b[0m       \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[1;32m--> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=282'>283</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=284'>285</a>\u001b[0m g \u001b[39m=\u001b[39m ops\u001b[39m.\u001b[39mget_default_graph()\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=285'>286</a>\u001b[0m tensor_value \u001b[39m=\u001b[39m attr_value_pb2\u001b[39m.\u001b[39mAttrValue()\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:308\u001b[0m, in \u001b[0;36m_constant_eager_impl\u001b[1;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=305'>306</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_constant_eager_impl\u001b[39m(ctx, value, dtype, shape, verify_shape):\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=306'>307</a>\u001b[0m   \u001b[39m\"\"\"Creates a constant on the current device.\"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=307'>308</a>\u001b[0m   t \u001b[39m=\u001b[39m convert_to_eager_tensor(value, ctx, dtype)\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=308'>309</a>\u001b[0m   \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=309'>310</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m t\n","File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\tf_gpu\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:106\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=103'>104</a>\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[0;32m    <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=104'>105</a>\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m--> <a href='file:///c%3A/tools/Anaconda3/envs/tf_gpu/lib/site-packages/tensorflow/python/framework/constant_op.py?line=105'>106</a>\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n","\u001b[1;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."]}],"source":["# Define data loaders.\n","train_loader = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n","validation_loader = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n","\n","batch_size = 1\n","# Augment the on the fly during training.\n","train_dataset = (\n","    train_loader.shuffle(len(x_train))\n","    .map(train_preprocessing)\n","    .batch(batch_size)\n","    .prefetch(2)\n",")\n","# Only rescale.\n","validation_dataset = (\n","    validation_loader.shuffle(len(x_val))\n","    .map(validation_preprocessing)\n","    .batch(batch_size)\n","    .prefetch(2)\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_gpus = 2\n","devices = tf.config.list_physical_devices('GPU')\n","devices_names = [d.name.split('e:')[1] for d in devices]\n","print(devices_names)\n","mirrored_strategy = tf.distribute.MirroredStrategy(\n","           devices=devices_names[:n_gpus])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","\n","data = train_dataset.take(1)\n","images, labels = list(data)[0]\n","images = images.numpy()\n","image = images[0]\n","print(\"Dimension of the CT scan is:\", image.shape)\n","plt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def plot_slices(num_rows, num_columns, width, height, data):\n","    \"\"\"Plot a montage of 20 CT slices\"\"\"\n","    data = np.rot90(np.array(data))\n","    data = np.transpose(data)\n","    data = np.reshape(data, (num_rows, num_columns, width, height))\n","    rows_data, columns_data = data.shape[0], data.shape[1]\n","    heights = [slc[0].shape[0] for slc in data]\n","    widths = [slc.shape[1] for slc in data[0]]\n","    fig_width = 12.0\n","    fig_height = fig_width * sum(heights) / sum(widths)\n","    f, axarr = plt.subplots(\n","        rows_data,\n","        columns_data,\n","        figsize=(fig_width, fig_height),\n","        gridspec_kw={\"height_ratios\": heights},\n","    )\n","    for i in range(rows_data):\n","        for j in range(columns_data):\n","            axarr[i, j].imshow(data[i][j], cmap=\"gray\")\n","            axarr[i, j].axis(\"off\")\n","    plt.subplots_adjust(wspace=0, hspace=0, left=0, right=1, bottom=0, top=1)\n","    plt.show()\n","\n","\n","# Visualize montage of slices.\n","# 4 rows and 10 columns for 100 slices of the CT scan.\n","plot_slices(4, 10, 83, 104, image[:, :, :40])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_model(width=83, height=104, depth=81):\n","    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n","\n","    inputs = keras.Input((width, height, depth, 1))\n","\n","    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n","    x = layers.MaxPool3D(pool_size=2)(x)\n","    x = layers.BatchNormalization()(x)\n","\n","    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(x)\n","    x = layers.MaxPool3D(pool_size=2)(x)\n","    x = layers.BatchNormalization()(x)\n","\n","    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n","    x = layers.MaxPool3D(pool_size=2)(x)\n","    x = layers.BatchNormalization()(x)\n","\n","    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n","    x = layers.MaxPool3D(pool_size=2)(x)\n","    x = layers.BatchNormalization()(x)\n","\n","    x = layers.GlobalAveragePooling3D()(x)\n","    x = layers.Dense(units=512, activation=\"relu\")(x)\n","    x = layers.Dropout(0.3)(x)\n","\n","    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n","\n","    # Define the model.\n","    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n","    return model\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["n_gpus = 2\n","devices = tf.config.list_physical_devices('GPU')\n","devices_names = [d.name.split('e:')[1] for d in devices]\n","print(devices_names)\n","mirrored_strategy = tf.distribute.MirroredStrategy(\n","           devices=devices_names[:n_gpus])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Compile model.\n","with mirrored_strategy.scope():\n","    # Build model.\n","    model = get_model(width=83, height=104, depth=81)\n","model.summary()\n","initial_learning_rate = 0.0001 * n_gpus\n","lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n","    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",")\n","model.compile(\n","    loss=\"binary_crossentropy\",\n","    optimizer=keras.optimizers.Adam(learning_rate=lr_schedule),\n","    metrics=[\"acc\"],\n",")\n","\n","# Define callbacks.\n","checkpoint_cb = keras.callbacks.ModelCheckpoint(\n","    \"3d_image_classification.h5\", save_best_only=True\n",")\n","early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_acc\", patience=15)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Train the model, doing validation at the end of each epoch\n","epochs = 100\n","model.fit(\n","    train_dataset,\n","    validation_data=validation_dataset,\n","    epochs=epochs,\n","    shuffle=True,\n","    verbose=2,\n","    callbacks=[checkpoint_cb, early_stopping_cb],\n",")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMFJrVko95UxCBeAuskcHlt","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}
