{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R8sq6jz4Cghk"
   },
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2558,
     "status": "ok",
     "timestamp": 1674767789094,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "qlxl2yW_JEWt"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\requests\\compat.py:11\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'chardet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtfds\u001b[39;00m\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\__init__.py:43\u001b[0m\n\u001b[0;32m     41\u001b[0m _TIMESTAMP_IMPORT_STARTS \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[1;32m---> 43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01m_tfds_logging\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlogging\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m call_metadata \u001b[38;5;28;01mas\u001b[39;00m _call_metadata\n\u001b[0;32m     46\u001b[0m _metadata \u001b[38;5;241m=\u001b[39m _call_metadata\u001b[38;5;241m.\u001b[39mCallMetadata()\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\__init__.py:22\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Allow to use `tfds.core.Path` in dataset implementation which seems more\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# natural than having to import a third party module.\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01metils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mepath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m community\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BeamBasedBuilder\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_builder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BuilderConfig\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\community\\__init__.py:18\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# coding=utf-8\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Copyright 2022 The TensorFlow Datasets Authors.\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# limitations under the License.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"Community dataset API.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mock_builtin_to_use_gfile\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhuggingface_wrapper\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mock_huggingface_import\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommunity\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m builder_cls_from_module\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\community\\huggingface_wrapper.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01munittest\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mock\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01metils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m epath\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_builder\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_info\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m download\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_builder.py:33\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01metils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m epath\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_info\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_metadata\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decode\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\dataset_info.py:51\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m splits \u001b[38;5;28;01mas\u001b[39;00m splits_lib\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature \u001b[38;5;28;01mas\u001b[39;00m feature_lib\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m top_level_feature\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproto\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dataset_info_pb2\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\features\\__init__.py:38\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_feature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Encoding\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtensor_feature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[1;32m---> 38\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext_feature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Text\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslation_feature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Translation\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtranslation_feature\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TranslationVariableLanguages\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\features\\text_feature.py:25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mabsl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text \u001b[38;5;28;01mas\u001b[39;00m text_lib\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m feature \u001b[38;5;28;01mas\u001b[39;00m feature_lib\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeatures\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tensor_feature\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\deprecated\\__init__.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"Deprecated symbols.\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdeprecated\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecksums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_checksums_dir\n\u001b[0;32m     21\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madd_checksums_dir\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     24\u001b[0m ]\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\download\\__init__.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m\"\"\"`tfds.download.DownloadManager` API.\"\"\"\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchecksums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m add_checksums_dir\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadConfig\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload_manager\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadManager\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownloader\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DownloadError\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\download\\download_manager.py:32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m checksums\n\u001b[1;32m---> 32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m downloader\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m extractor\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdownload\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m kaggle\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow_datasets\\core\\download\\downloader.py:31\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01metils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m epath\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpromise\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m units\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow_datasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m utils\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\requests\\__init__.py:45\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RequestsDependencyWarning\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     48\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__ \u001b[38;5;28;01mas\u001b[39;00m charset_normalizer_version\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\requests\\exceptions.py:9\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mrequests.exceptions\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03mThis module contains the set of Requests' exceptions.\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01murllib3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m BaseHTTPError\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m CompatJSONDecodeError\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRequestException\u001b[39;00m(\u001b[38;5;167;01mIOError\u001b[39;00m):\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;124;03m\"\"\"There was an ambiguous exception that occurred while handling your\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    request.\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\requests\\compat.py:13\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m---> 13\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchardet\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# -------\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Pythons\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# -------\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Syntax sugar.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\charset_normalizer\\__init__.py:23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mCharset-Normalizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, VERSION\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\charset_normalizer\\api.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     PathLike \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.PathLike[str]\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mess_ratio\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharsetMatches, CharsetMatch\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n",
      "\u001b[1;31mAttributeError\u001b[0m: partially initialized module 'charset_normalizer' has no attribute 'md__mypyc' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 371,
     "status": "ok",
     "timestamp": 1674767789460,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "lFKVQP75QcE1",
    "outputId": "3ecf2e22-789f-4d1a-be4f-df0c6dd38593"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU'),\n",
       " PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.list_physical_devices('GPU')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1674767789460,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "2YRW40NfONVP"
   },
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 70_000\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "6664525f178b4ec89947a11fcec25b5f",
      "d85a5e3e37174af587aa52763c17bee2",
      "f1a0428c25cb4386839da293c4a89d42",
      "319f09a3c255420fa7b7b1a5ab4d126d",
      "b70b33607fa8435b8d7d87e2b5c12578",
      "2776b7c6667d4f228ca99a44915da6ba",
      "89927c3fe4a84cd6aa24ea063b3d3773",
      "c128d295868b43f6b743107cd1c4dc48",
      "f8c1d3985e3b49c7bee588ca047187a3",
      "6cde8879fd1742e1aa6db04ad7fe297f",
      "e8eb8c0e354d4ba9a31d3ea8054545c0"
     ]
    },
    "executionInfo": {
     "elapsed": 4153,
     "status": "ok",
     "timestamp": 1674767793611,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "jl0GPwwR7hzs",
    "outputId": "12edc7e5-2ea5-439c-d62a-5457363533bb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/2 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/3 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...: 0 MiB [00:00, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/1 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:   0%|          | 0/4 [00:00<?, ? url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00, 11.03 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  25%|██▌       | 1/4 [00:00<00:00, 10.45 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00, 17.92 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00, 17.92 url/s]\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:   0%|          | 0/1 [00:00<?, ? file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:   0%|          | 0/10 [00:00<?, ? MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  8.16 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00, 17.92 url/s]\n",
      "Dl Size...:  10%|█         | 1/10 [00:00<00:01,  5.64 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  50%|█████     | 2/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|██        | 2/10 [00:00<00:01,  5.64 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  20%|██        | 2/10 [00:00<00:01,  5.64 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  30%|███       | 3/10 [00:00<00:01,  5.64 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  40%|████      | 4/10 [00:00<00:01,  5.64 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  50%|█████     | 5/10 [00:00<00:00,  5.64 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  60%|██████    | 6/10 [00:00<00:00,  5.64 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  70%|███████   | 7/10 [00:00<00:00,  5.64 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 2/2 [00:00<00:00,  8.16 file/s]\u001b[A\u001b[A\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]\n",
      "Dl Size...:  80%|████████  | 8/10 [00:00<00:00, 32.40 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...:  90%|█████████ | 9/10 [00:00<00:00, 32.40 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00, 32.40 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00, 32.40 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  67%|██████▋   | 2/3 [00:00<00:00,  8.16 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...:  75%|███████▌  | 3/4 [00:00<00:00, 17.92 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00, 32.40 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:00<00:00, 10.72 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00, 32.40 MiB/s]\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:00<00:00, 10.72 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00, 32.40 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...:  75%|███████▌  | 3/4 [00:00<00:00,  8.86 file/s]\u001b[A\u001b[A\n",
      "\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:00<00:00, 10.72 url/s]6 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00, 32.40 MiB/s]\u001b[A\n",
      "\n",
      "Extraction completed...: 100%|██████████| 4/4 [00:00<00:00,  5.49 file/s]\u001b[A\u001b[A\n",
      "Dl Size...: 100%|██████████| 10/10 [00:00<00:00, 13.69 MiB/s]\n",
      "Dl Completed...: 100%|██████████| 4/4 [00:00<00:00,  5.46 url/s]\n",
      "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating train examples...: 1 examples [00:00,  7.98 examples/s]\u001b[A\n",
      "Generating train examples...: 322 examples [00:00, 1708.94 examples/s]\u001b[A\n",
      "Generating train examples...: 651 examples [00:00, 2385.19 examples/s]\u001b[A\n",
      "Generating train examples...: 984 examples [00:00, 2738.93 examples/s]\u001b[A\n",
      "Generating train examples...: 1325 examples [00:00, 2969.01 examples/s]\u001b[A\n",
      "Generating train examples...: 1676 examples [00:00, 3143.68 examples/s]\u001b[A\n",
      "Generating train examples...: 2027 examples [00:00, 3255.82 examples/s]\u001b[A\n",
      "Generating train examples...: 2367 examples [00:00, 3295.28 examples/s]\u001b[A\n",
      "Generating train examples...: 2710 examples [00:00, 3331.10 examples/s]\u001b[A\n",
      "Generating train examples...: 3051 examples [00:01, 3349.39 examples/s]\u001b[A\n",
      "Generating train examples...: 3392 examples [00:01, 3361.95 examples/s]\u001b[A\n",
      "Generating train examples...: 3740 examples [00:01, 3391.77 examples/s]\u001b[A\n",
      "Generating train examples...: 4091 examples [00:01, 3421.48 examples/s]\u001b[A\n",
      "Generating train examples...: 4441 examples [00:01, 3439.13 examples/s]\u001b[A\n",
      "Generating train examples...: 4787 examples [00:01, 3439.46 examples/s]\u001b[A\n",
      "Generating train examples...: 5132 examples [00:01, 3426.49 examples/s]\u001b[A\n",
      "Generating train examples...: 5475 examples [00:01, 3411.53 examples/s]\u001b[A\n",
      "Generating train examples...: 5818 examples [00:01, 3411.19 examples/s]\u001b[A\n",
      "Generating train examples...: 6165 examples [00:01, 3422.87 examples/s]\u001b[A\n",
      "Generating train examples...: 6510 examples [00:02, 3425.07 examples/s]\u001b[A\n",
      "Generating train examples...: 6860 examples [00:02, 3441.55 examples/s]\u001b[A\n",
      "Generating train examples...: 7206 examples [00:02, 3441.15 examples/s]\u001b[A\n",
      "Generating train examples...: 7551 examples [00:02, 3437.90 examples/s]\u001b[A\n",
      "Generating train examples...: 7899 examples [00:02, 3444.55 examples/s]\u001b[A\n",
      "Generating train examples...: 8244 examples [00:02, 3440.27 examples/s]\u001b[A\n",
      "Generating train examples...: 8589 examples [00:02, 3437.28 examples/s]\u001b[A\n",
      "Generating train examples...: 8934 examples [00:02, 3435.18 examples/s]\u001b[A\n",
      "Generating train examples...: 9278 examples [00:02, 3430.72 examples/s]\u001b[A\n",
      "Generating train examples...: 9625 examples [00:02, 3436.56 examples/s]\u001b[A\n",
      "Generating train examples...: 9969 examples [00:03, 3421.52 examples/s]\u001b[A\n",
      "Generating train examples...: 10320 examples [00:03, 3442.00 examples/s]\u001b[A\n",
      "Generating train examples...: 10667 examples [00:03, 3444.45 examples/s]\u001b[A\n",
      "Generating train examples...: 11017 examples [00:03, 3455.10 examples/s]\u001b[A\n",
      "Generating train examples...: 11364 examples [00:03, 3453.62 examples/s]\u001b[A\n",
      "Generating train examples...: 11714 examples [00:03, 3461.53 examples/s]\u001b[A\n",
      "Generating train examples...: 12062 examples [00:03, 3461.10 examples/s]\u001b[A\n",
      "Generating train examples...: 12409 examples [00:03, 3457.82 examples/s]\u001b[A\n",
      "Generating train examples...: 12755 examples [00:03, 3452.55 examples/s]\u001b[A\n",
      "Generating train examples...: 13101 examples [00:03, 3428.48 examples/s]\u001b[A\n",
      "Generating train examples...: 13444 examples [00:04, 3412.98 examples/s]\u001b[A\n",
      "Generating train examples...: 13791 examples [00:04, 3424.08 examples/s]\u001b[A\n",
      "Generating train examples...: 14135 examples [00:04, 3422.96 examples/s]\u001b[A\n",
      "Generating train examples...: 14478 examples [00:04, 3408.69 examples/s]\u001b[A\n",
      "Generating train examples...: 14819 examples [00:04, 3393.22 examples/s]\u001b[A\n",
      "Generating train examples...: 15159 examples [00:04, 3371.59 examples/s]\u001b[A\n",
      "Generating train examples...: 15501 examples [00:04, 3380.19 examples/s]\u001b[A\n",
      "Generating train examples...: 15840 examples [00:04, 3367.37 examples/s]\u001b[A\n",
      "Generating train examples...: 16185 examples [00:04, 3386.15 examples/s]\u001b[A\n",
      "Generating train examples...: 16528 examples [00:04, 3392.94 examples/s]\u001b[A\n",
      "Generating train examples...: 16870 examples [00:05, 3395.19 examples/s]\u001b[A\n",
      "Generating train examples...: 17218 examples [00:05, 3414.63 examples/s]\u001b[A\n",
      "Generating train examples...: 17566 examples [00:05, 3428.25 examples/s]\u001b[A\n",
      "Generating train examples...: 17916 examples [00:05, 3443.76 examples/s]\u001b[A\n",
      "Generating train examples...: 18267 examples [00:05, 3457.61 examples/s]\u001b[A\n",
      "Generating train examples...: 18617 examples [00:05, 3464.32 examples/s]\u001b[A\n",
      "Generating train examples...: 18964 examples [00:05, 3449.83 examples/s]\u001b[A\n",
      "Generating train examples...: 19309 examples [00:05, 3443.98 examples/s]\u001b[A\n",
      "Generating train examples...: 19654 examples [00:05, 3425.63 examples/s]\u001b[A\n",
      "Generating train examples...: 19997 examples [00:05, 3410.98 examples/s]\u001b[A\n",
      "Generating train examples...: 20339 examples [00:06, 3387.82 examples/s]\u001b[A\n",
      "Generating train examples...: 20678 examples [00:06, 3353.03 examples/s]\u001b[A\n",
      "Generating train examples...: 21016 examples [00:06, 3355.30 examples/s]\u001b[A\n",
      "Generating train examples...: 21352 examples [00:06, 3350.98 examples/s]\u001b[A\n",
      "Generating train examples...: 21695 examples [00:06, 3368.71 examples/s]\u001b[A\n",
      "Generating train examples...: 22039 examples [00:06, 3384.14 examples/s]\u001b[A\n",
      "Generating train examples...: 22385 examples [00:06, 3400.91 examples/s]\u001b[A\n",
      "Generating train examples...: 22732 examples [00:06, 3415.67 examples/s]\u001b[A\n",
      "Generating train examples...: 23078 examples [00:06, 3423.01 examples/s]\u001b[A\n",
      "Generating train examples...: 23421 examples [00:06, 3409.12 examples/s]\u001b[A\n",
      "Generating train examples...: 23762 examples [00:07, 3403.54 examples/s]\u001b[A\n",
      "Generating train examples...: 24108 examples [00:07, 3414.53 examples/s]\u001b[A\n",
      "Generating train examples...: 24455 examples [00:07, 3425.12 examples/s]\u001b[A\n",
      "Generating train examples...: 24798 examples [00:07, 3410.58 examples/s]\u001b[A\n",
      "Generating train examples...: 25140 examples [00:07, 3407.55 examples/s]\u001b[A\n",
      "Generating train examples...: 25481 examples [00:07, 3402.46 examples/s]\u001b[A\n",
      "Generating train examples...: 25822 examples [00:07, 3388.83 examples/s]\u001b[A\n",
      "Generating train examples...: 26166 examples [00:07, 3399.19 examples/s]\u001b[A\n",
      "Generating train examples...: 26512 examples [00:07, 3411.47 examples/s]\u001b[A\n",
      "Generating train examples...: 26854 examples [00:07, 3388.07 examples/s]\u001b[A\n",
      "Generating train examples...: 27193 examples [00:08, 3353.13 examples/s]\u001b[A\n",
      "Generating train examples...: 27529 examples [00:08, 3329.87 examples/s]\u001b[A\n",
      "Generating train examples...: 27863 examples [00:08, 3327.21 examples/s]\u001b[A\n",
      "Generating train examples...: 28196 examples [00:08, 3322.38 examples/s]\u001b[A\n",
      "Generating train examples...: 28533 examples [00:08, 3330.85 examples/s]\u001b[A\n",
      "Generating train examples...: 28869 examples [00:08, 3333.81 examples/s]\u001b[A\n",
      "Generating train examples...: 29203 examples [00:08, 3310.35 examples/s]\u001b[A\n",
      "Generating train examples...: 29536 examples [00:08, 3310.53 examples/s]\u001b[A\n",
      "Generating train examples...: 29875 examples [00:08, 3328.48 examples/s]\u001b[A\n",
      "Generating train examples...: 30223 examples [00:09, 3367.85 examples/s]\u001b[A\n",
      "Generating train examples...: 30560 examples [00:09, 3352.79 examples/s]\u001b[A\n",
      "Generating train examples...: 30896 examples [00:09, 3339.32 examples/s]\u001b[A\n",
      "Generating train examples...: 31230 examples [00:09, 3304.51 examples/s]\u001b[A\n",
      "Generating train examples...: 31561 examples [00:09, 3300.50 examples/s]\u001b[A\n",
      "Generating train examples...: 31895 examples [00:09, 3306.59 examples/s]\u001b[A\n",
      "Generating train examples...: 32238 examples [00:09, 3337.15 examples/s]\u001b[A\n",
      "Generating train examples...: 32581 examples [00:09, 3359.05 examples/s]\u001b[A\n",
      "Generating train examples...: 32922 examples [00:09, 3368.47 examples/s]\u001b[A\n",
      "Generating train examples...: 33264 examples [00:09, 3378.05 examples/s]\u001b[A\n",
      "Generating train examples...: 33610 examples [00:10, 3396.68 examples/s]\u001b[A\n",
      "Generating train examples...: 33951 examples [00:10, 3394.81 examples/s]\u001b[A\n",
      "Generating train examples...: 34293 examples [00:10, 3396.51 examples/s]\u001b[A\n",
      "Generating train examples...: 34640 examples [00:10, 3412.61 examples/s]\u001b[A\n",
      "Generating train examples...: 34982 examples [00:10, 3398.87 examples/s]\u001b[A\n",
      "Generating train examples...: 35331 examples [00:10, 3420.17 examples/s]\u001b[A\n",
      "Generating train examples...: 35680 examples [00:10, 3435.11 examples/s]\u001b[A\n",
      "Generating train examples...: 36027 examples [00:10, 3439.63 examples/s]\u001b[A\n",
      "Generating train examples...: 36371 examples [00:10, 3433.84 examples/s]\u001b[A\n",
      "Generating train examples...: 36715 examples [00:10, 3427.65 examples/s]\u001b[A\n",
      "Generating train examples...: 37058 examples [00:11, 3411.93 examples/s]\u001b[A\n",
      "Generating train examples...: 37400 examples [00:11, 3408.51 examples/s]\u001b[A\n",
      "Generating train examples...: 37741 examples [00:11, 3403.09 examples/s]\u001b[A\n",
      "Generating train examples...: 38088 examples [00:11, 3417.22 examples/s]\u001b[A\n",
      "Generating train examples...: 38437 examples [00:11, 3433.05 examples/s]\u001b[A\n",
      "Generating train examples...: 38781 examples [00:11, 3419.08 examples/s]\u001b[A\n",
      "Generating train examples...: 39128 examples [00:11, 3428.38 examples/s]\u001b[A\n",
      "Generating train examples...: 39476 examples [00:11, 3437.89 examples/s]\u001b[A\n",
      "Generating train examples...: 39825 examples [00:11, 3447.53 examples/s]\u001b[A\n",
      "Generating train examples...: 40172 examples [00:11, 3448.32 examples/s]\u001b[A\n",
      "Generating train examples...: 40522 examples [00:12, 3457.81 examples/s]\u001b[A\n",
      "Generating train examples...: 40868 examples [00:12, 3432.16 examples/s]\u001b[A\n",
      "Generating train examples...: 41212 examples [00:12, 3428.18 examples/s]\u001b[A\n",
      "Generating train examples...: 41558 examples [00:12, 3431.79 examples/s]\u001b[A\n",
      "Generating train examples...: 41907 examples [00:12, 3443.24 examples/s]\u001b[A\n",
      "Generating train examples...: 42252 examples [00:12, 3439.36 examples/s]\u001b[A\n",
      "Generating train examples...: 42596 examples [00:12, 3433.66 examples/s]\u001b[A\n",
      "Generating train examples...: 42940 examples [00:12, 3399.40 examples/s]\u001b[A\n",
      "Generating train examples...: 43281 examples [00:12, 3386.75 examples/s]\u001b[A\n",
      "Generating train examples...: 43620 examples [00:12, 3381.95 examples/s]\u001b[A\n",
      "Generating train examples...: 43959 examples [00:13, 3358.70 examples/s]\u001b[A\n",
      "Generating train examples...: 44298 examples [00:13, 3362.19 examples/s]\u001b[A\n",
      "Generating train examples...: 44636 examples [00:13, 3361.80 examples/s]\u001b[A\n",
      "Generating train examples...: 44974 examples [00:13, 3361.47 examples/s]\u001b[A\n",
      "Generating train examples...: 45311 examples [00:13, 3358.25 examples/s]\u001b[A\n",
      "Generating train examples...: 45650 examples [00:13, 3361.95 examples/s]\u001b[A\n",
      "Generating train examples...: 45990 examples [00:13, 3367.53 examples/s]\u001b[A\n",
      "Generating train examples...: 46327 examples [00:13, 3342.66 examples/s]\u001b[A\n",
      "Generating train examples...: 46667 examples [00:13, 3353.98 examples/s]\u001b[A\n",
      "Generating train examples...: 47007 examples [00:13, 3361.92 examples/s]\u001b[A\n",
      "Generating train examples...: 47344 examples [00:14, 3348.66 examples/s]\u001b[A\n",
      "Generating train examples...: 47682 examples [00:14, 3352.25 examples/s]\u001b[A\n",
      "Generating train examples...: 48025 examples [00:14, 3369.65 examples/s]\u001b[A\n",
      "Generating train examples...: 48366 examples [00:14, 3375.90 examples/s]\u001b[A\n",
      "Generating train examples...: 48711 examples [00:14, 3392.19 examples/s]\u001b[A\n",
      "Generating train examples...: 49057 examples [00:14, 3406.59 examples/s]\u001b[A\n",
      "Generating train examples...: 49403 examples [00:14, 3416.67 examples/s]\u001b[A\n",
      "Generating train examples...: 49750 examples [00:14, 3426.71 examples/s]\u001b[A\n",
      "Generating train examples...: 50096 examples [00:14, 3430.77 examples/s]\u001b[A\n",
      "Generating train examples...: 50440 examples [00:14, 3427.64 examples/s]\u001b[A\n",
      "Generating train examples...: 50783 examples [00:15, 3392.24 examples/s]\u001b[A\n",
      "Generating train examples...: 51123 examples [00:15, 3388.76 examples/s]\u001b[A\n",
      "Generating train examples...: 51469 examples [00:15, 3404.13 examples/s]\u001b[A\n",
      "Generating train examples...: 51810 examples [00:15, 3400.04 examples/s]\u001b[A\n",
      "Generating train examples...: 52156 examples [00:15, 3412.07 examples/s]\u001b[A\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train examples...: 52502 examples [00:15, 3420.50 examples/s]\u001b[A\n",
      "Generating train examples...: 52845 examples [00:15, 3407.37 examples/s]\u001b[A\n",
      "Generating train examples...: 53186 examples [00:15, 3402.33 examples/s]\u001b[A\n",
      "Generating train examples...: 53532 examples [00:15, 3413.68 examples/s]\u001b[A\n",
      "Generating train examples...: 53876 examples [00:15, 3415.67 examples/s]\u001b[A\n",
      "Generating train examples...: 54218 examples [00:16, 3390.99 examples/s]\u001b[A\n",
      "Generating train examples...: 54563 examples [00:16, 3402.71 examples/s]\u001b[A\n",
      "Generating train examples...: 54906 examples [00:16, 3405.01 examples/s]\u001b[A\n",
      "Generating train examples...: 55253 examples [00:16, 3418.53 examples/s]\u001b[A\n",
      "Generating train examples...: 55603 examples [00:16, 3436.94 examples/s]\u001b[A\n",
      "Generating train examples...: 55947 examples [00:16, 3431.95 examples/s]\u001b[A\n",
      "Generating train examples...: 56292 examples [00:16, 3431.46 examples/s]\u001b[A\n",
      "Generating train examples...: 56636 examples [00:16, 3417.97 examples/s]\u001b[A\n",
      "Generating train examples...: 56978 examples [00:16, 3412.73 examples/s]\u001b[A\n",
      "Generating train examples...: 57320 examples [00:16, 3388.95 examples/s]\u001b[A\n",
      "Generating train examples...: 57659 examples [00:17, 3353.76 examples/s]\u001b[A\n",
      "Generating train examples...: 57999 examples [00:17, 3361.72 examples/s]\u001b[A\n",
      "Generating train examples...: 58343 examples [00:17, 3379.17 examples/s]\u001b[A\n",
      "Generating train examples...: 58686 examples [00:17, 3388.50 examples/s]\u001b[A\n",
      "Generating train examples...: 59028 examples [00:17, 3392.08 examples/s]\u001b[A\n",
      "Generating train examples...: 59375 examples [00:17, 3409.46 examples/s]\u001b[A\n",
      "Generating train examples...: 59722 examples [00:17, 3421.65 examples/s]\u001b[A\n",
      "                                                                        \u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-train.tfrecord*...:   0%|          | 0/60000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-train.tfrecord*...:   6%|▌         | 3731/60000 [00:00<00:01, 37096.53 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-train.tfrecord*...:  18%|█▊        | 11050/60000 [00:00<00:00, 58067.16 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-train.tfrecord*...:  31%|███       | 18381/60000 [00:00<00:00, 64835.20 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-train.tfrecord*...:  43%|████▎     | 25968/60000 [00:00<00:00, 69019.90 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-train.tfrecord*...:  56%|█████▌    | 33523/60000 [00:00<00:00, 71218.84 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-train.tfrecord*...:  68%|██████▊   | 40881/60000 [00:00<00:00, 71878.65 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-train.tfrecord*...:  80%|████████  | 48266/60000 [00:00<00:00, 72385.10 examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-train.tfrecord*...:  93%|█████████▎| 55752/60000 [00:00<00:00, 73036.62 examples/s]\u001b[A\n",
      "Generating splits...:  50%|█████     | 1/2 [00:18<00:18, 18.69s/ splits]                                                                                               \u001b[A\n",
      "Generating test examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "Generating test examples...: 274 examples [00:00, 2724.28 examples/s]\u001b[A\n",
      "Generating test examples...: 596 examples [00:00, 3005.04 examples/s]\u001b[A\n",
      "Generating test examples...: 921 examples [00:00, 3108.41 examples/s]\u001b[A\n",
      "Generating test examples...: 1237 examples [00:00, 3121.64 examples/s]\u001b[A\n",
      "Generating test examples...: 1556 examples [00:00, 3139.72 examples/s]\u001b[A\n",
      "Generating test examples...: 1870 examples [00:00, 3133.71 examples/s]\u001b[A\n",
      "Generating test examples...: 2194 examples [00:00, 3162.41 examples/s]\u001b[A\n",
      "Generating test examples...: 2520 examples [00:00, 3187.54 examples/s]\u001b[A\n",
      "Generating test examples...: 2844 examples [00:00, 3198.15 examples/s]\u001b[A\n",
      "Generating test examples...: 3170 examples [00:01, 3211.48 examples/s]\u001b[A\n",
      "Generating test examples...: 3495 examples [00:01, 3217.59 examples/s]\u001b[A\n",
      "Generating test examples...: 3817 examples [00:01, 3203.07 examples/s]\u001b[A\n",
      "Generating test examples...: 4139 examples [00:01, 3202.63 examples/s]\u001b[A\n",
      "Generating test examples...: 4460 examples [00:01, 3199.32 examples/s]\u001b[A\n",
      "Generating test examples...: 4786 examples [00:01, 3211.98 examples/s]\u001b[A\n",
      "Generating test examples...: 5110 examples [00:01, 3214.84 examples/s]\u001b[A\n",
      "Generating test examples...: 5433 examples [00:01, 3213.84 examples/s]\u001b[A\n",
      "Generating test examples...: 5757 examples [00:01, 3216.14 examples/s]\u001b[A\n",
      "Generating test examples...: 6079 examples [00:01, 3192.80 examples/s]\u001b[A\n",
      "Generating test examples...: 6399 examples [00:02, 3189.15 examples/s]\u001b[A\n",
      "Generating test examples...: 6721 examples [00:02, 3192.85 examples/s]\u001b[A\n",
      "Generating test examples...: 7047 examples [00:02, 3207.38 examples/s]\u001b[A\n",
      "Generating test examples...: 7372 examples [00:02, 3214.58 examples/s]\u001b[A\n",
      "Generating test examples...: 7694 examples [00:02, 3191.75 examples/s]\u001b[A\n",
      "Generating test examples...: 8014 examples [00:02, 3170.00 examples/s]\u001b[A\n",
      "Generating test examples...: 8335 examples [00:02, 3176.46 examples/s]\u001b[A\n",
      "Generating test examples...: 8653 examples [00:02, 3167.49 examples/s]\u001b[A\n",
      "Generating test examples...: 8970 examples [00:02, 3125.86 examples/s]\u001b[A\n",
      "Generating test examples...: 9283 examples [00:02, 3103.56 examples/s]\u001b[A\n",
      "Generating test examples...: 9594 examples [00:03, 3082.11 examples/s]\u001b[A\n",
      "Generating test examples...: 9905 examples [00:03, 3085.10 examples/s]\u001b[A\n",
      "                                                                      \u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-test.tfrecord*...:   0%|          | 0/10000 [00:00<?, ? examples/s]\u001b[A\n",
      "Shuffling C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1.incompleteO8A3U3\\mnist-test.tfrecord*...:  71%|███████   | 7092/10000 [00:00<00:00, 70515.40 examples/s]\u001b[A\n",
      "                                                                                                                                                                     \u001b[A\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset mnist downloaded and prepared to C:\\Users\\007303173\\tensorflow_datasets\\mnist\\3.0.1. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "mnist_dataset, mnist_info =tfds.load(name='mnist', with_info=True, as_supervised=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 225,
     "status": "ok",
     "timestamp": 1674767793830,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "oYwa9glXOZUd"
   },
   "outputs": [],
   "source": [
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gXAn96IC9pZn"
   },
   "source": [
    "The scale method will make all values be between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 223,
     "status": "ok",
     "timestamp": 1674767793830,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "G_zQ2oQD8VY2"
   },
   "outputs": [],
   "source": [
    "def scale(image, label):\n",
    "  image= tf.cast(image, tf.float32)\n",
    "  image /= 225.\n",
    "  return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1674767793830,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "zGVPl2aD8v1I"
   },
   "outputs": [],
   "source": [
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uQpJnc22_uU-"
   },
   "source": [
    "Split the data for testing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674767793831,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "Yb7TN8Km9hH-"
   },
   "outputs": [],
   "source": [
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1674767793831,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "PAYxl68R_BTD"
   },
   "outputs": [],
   "source": [
    "num_test_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_test_samples= tf.cast(num_test_samples, tf.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GpUxBk7nAx22"
   },
   "source": [
    "BUFFER_SIZE is the size opf the batch being shuffles in this case its the entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674767793832,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "zR62XK5z_YSl"
   },
   "outputs": [],
   "source": [
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1674767793832,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "tmLMg_j6__Sb"
   },
   "outputs": [],
   "source": [
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674767793833,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "uImAiPW3AIIi"
   },
   "outputs": [],
   "source": [
    "train_data = train_data.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H5tAiNodBkIs"
   },
   "source": [
    "The validation and test sets dont need to be batched. Since we dont backward propiagate on them, however the model expects them to be batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674767793833,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "z9FaZLDpBjc8"
   },
   "outputs": [],
   "source": [
    "validation_data = validation_data.batch(num_validation_samples)\n",
    "test_data = test_data.batch(num_test_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d1u_BLpHCmUy"
   },
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HO7F4k0DxL0"
   },
   "source": [
    "1.  The fisrt layer has a 5x5 kernel it produces 50 feature maps.\n",
    "2.  The second layer has a 3x3 kernel it produces 50 feature maps\n",
    "3.  The dense layer output is 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "executionInfo": {
     "elapsed": 169,
     "status": "ok",
     "timestamp": 1674767793992,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "8M30atHaCtX8"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(50, 5, activation = 'relu', input_shape = (28,28,1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Conv2D(50, 3, activation = 'relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size = (2,2)),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 212,
     "status": "ok",
     "timestamp": 1674767794202,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "OQUAzkH0EVz5",
    "outputId": "f89b12c7-7a5c-471d-c701-4c4e44c5ad74"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "___________________________________________________________________________\n",
      " Layer (type)                    Output Shape                  Param #     \n",
      "===========================================================================\n",
      " conv2d (Conv2D)                 (None, 24, 24, 50)            1300        \n",
      "                                                                           \n",
      " max_pooling2d (MaxPooling2D)    (None, 12, 12, 50)            0           \n",
      "                                                                           \n",
      " conv2d_1 (Conv2D)               (None, 10, 10, 50)            22550       \n",
      "                                                                           \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 5, 5, 50)              0           \n",
      "                                                                           \n",
      " flatten (Flatten)               (None, 1250)                  0           \n",
      "                                                                           \n",
      " dense (Dense)                   (None, 10)                    12510       \n",
      "                                                                           \n",
      "===========================================================================\n",
      "Total params: 36,360\n",
      "Trainable params: 36,360\n",
      "Non-trainable params: 0\n",
      "___________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary(line_length = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674767794202,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "gAYIG0tzGt1a"
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674767794203,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "efghUjBLHD6U"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1674767794203,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "oXSZS5AxIMQN"
   },
   "outputs": [],
   "source": [
    "early_stopping =tf.keras.callbacks.EarlyStopping(\n",
    "  monitor= 'val_loss',\n",
    "  mode = 'auto',\n",
    "  min_delta = 0, \n",
    "  patience = 2,\n",
    "  verbose = 0,\n",
    "  restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "BhTeysfD_5Yx"
   },
   "outputs": [],
   "source": [
    "log_dir = \"logs\\\\fit\\\\\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 127637,
     "status": "ok",
     "timestamp": 1674767921830,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "fX0O-FeYI2CZ",
    "outputId": "7df8ec0c-3b86-42e7-a641-d1e5f419183e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "422/422 - 51s - loss: 0.0314 - accuracy: 0.9904 - val_loss: 0.0346 - val_accuracy: 0.9890 - 51s/epoch - 120ms/step\n",
      "Epoch 2/20\n",
      "422/422 - 61s - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.0230 - val_accuracy: 0.9928 - 61s/epoch - 143ms/step\n",
      "Epoch 3/20\n",
      "422/422 - 62s - loss: 0.0242 - accuracy: 0.9924 - val_loss: 0.0204 - val_accuracy: 0.9932 - 62s/epoch - 148ms/step\n",
      "Epoch 4/20\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtensorboard_callback\u001b[49m\u001b[43m,\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[0;32m      7\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\keras\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\keras\\engine\\training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[0;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1648\u001b[0m ):\n\u001b[0;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[0;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[1;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_no_variable_creation_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[0;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[0;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    132\u001b[0m   (concrete_function,\n\u001b[0;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m     args,\n\u001b[0;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1750\u001b[0m     executing_eagerly)\n\u001b[0;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32mC:\\tools\\Anaconda3\\envs\\MNIST\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_data,\n",
    "    epochs = NUM_EPOCHS,\n",
    "    callbacks = [tensorboard_callback,early_stopping],\n",
    "    validation_data =validation_data,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdO5nIPr2Pnu"
   },
   "source": [
    "# Testing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1164,
     "status": "ok",
     "timestamp": 1674768045348,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "hozqVZhT20t3",
    "outputId": "0013de87-6163-4089-867a-88de34f0f706"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 243ms/step - loss: 2.3155 - accuracy: 0.1134\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy =  model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 179,
     "status": "ok",
     "timestamp": 1674768047103,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "CFtG1zKq2940",
    "outputId": "706edba5-8b00-430d-ae13-4dda8f419a48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0271. Test accuracy:  99.18%\n"
     ]
    }
   ],
   "source": [
    "print('Test loss: {0:.4f}. Test accuracy: {1: .2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dg8RERHt3d6P"
   },
   "source": [
    "Plotting Images and results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1674766767133,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "9xI_9ygH3bYE"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tQbJI9_M4Sfu"
   },
   "source": [
    "Split the test_data into 2 arrays, containing the images and correponding labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 499,
     "status": "ok",
     "timestamp": 1674768070208,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "V1cdpQO33rBw"
   },
   "outputs": [],
   "source": [
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEgt_DUT4pQV"
   },
   "source": [
    "Reshape the images into 28X28 form, suitable for matplotlib (original dimensions: (28x28x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "executionInfo": {
     "elapsed": 424,
     "status": "error",
     "timestamp": 1674768073171,
     "user": {
      "displayName": "Ezequiel Hernandez",
      "userId": "10229188064205579760"
     },
     "user_tz": 480
    },
    "id": "YDEV4KWM4o6p",
    "outputId": "134d471a-8fad-4a32-a03f-caebe49b1f7f"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-108c990837bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mreshape\u001b[0;34m(a, newshape, order)\u001b[0m\n\u001b[1;32m    296\u001b[0m            [5, 6]])\n\u001b[1;32m    297\u001b[0m     \"\"\"\n\u001b[0;32m--> 298\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'reshape'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 4704000 into shape (10000,28,28)"
     ]
    }
   ],
   "source": [
    "images_plot = np.reshape(images_test, (10000,28,28))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cC-pBGEd5X9V"
   },
   "source": [
    "The image to be displayed and tested"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U93aOYZT7Qgr"
   },
   "outputs": [],
   "source": [
    "i = 1\n",
    "plt.figures(figsize=(2,2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1],cmap='gray', aspect=\"auto\")\n",
    "plt.show\n",
    "print(\"Label: {}\".format(labels_test[i-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wv_7_Ovi8TNH"
   },
   "source": [
    "Obtain the model's prediction (logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q2NBZgHX8SDu"
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(images_test[i+1:i])\n",
    "probabilities = tf.nn,softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZUxVaa6WUIuD"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XZYLZefaUIDB"
   },
   "source": [
    "# Visualizing in tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B4G1nKZXURJv"
   },
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"logs/dir\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNSzu8q1jPnLb5jSqa4fjee",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "2776b7c6667d4f228ca99a44915da6ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "319f09a3c255420fa7b7b1a5ab4d126d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6cde8879fd1742e1aa6db04ad7fe297f",
      "placeholder": "​",
      "style": "IPY_MODEL_e8eb8c0e354d4ba9a31d3ea8054545c0",
      "value": " 5/5 [00:00&lt;00:00, 10.64 file/s]"
     }
    },
    "6664525f178b4ec89947a11fcec25b5f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_d85a5e3e37174af587aa52763c17bee2",
       "IPY_MODEL_f1a0428c25cb4386839da293c4a89d42",
       "IPY_MODEL_319f09a3c255420fa7b7b1a5ab4d126d"
      ],
      "layout": "IPY_MODEL_b70b33607fa8435b8d7d87e2b5c12578"
     }
    },
    "6cde8879fd1742e1aa6db04ad7fe297f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "89927c3fe4a84cd6aa24ea063b3d3773": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b70b33607fa8435b8d7d87e2b5c12578": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c128d295868b43f6b743107cd1c4dc48": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d85a5e3e37174af587aa52763c17bee2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2776b7c6667d4f228ca99a44915da6ba",
      "placeholder": "​",
      "style": "IPY_MODEL_89927c3fe4a84cd6aa24ea063b3d3773",
      "value": "Dl Completed...: 100%"
     }
    },
    "e8eb8c0e354d4ba9a31d3ea8054545c0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f1a0428c25cb4386839da293c4a89d42": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c128d295868b43f6b743107cd1c4dc48",
      "max": 5,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_f8c1d3985e3b49c7bee588ca047187a3",
      "value": 5
     }
    },
    "f8c1d3985e3b49c7bee588ca047187a3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
