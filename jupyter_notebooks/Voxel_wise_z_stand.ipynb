{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k64Z8hXNy-sh"
   },
   "source": [
    "#Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_iftfZn2Ndo",
    "outputId": "027459b3-252a-4ca7-f877-ed9a6d90b882"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "LABLE_FILE = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/ppdata/subj01/behav/responses.tsv'\n",
    "FMRI_DIR = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/GLM-fmri-data/subj01'\n",
    "FMRI_DIR_STND = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/standardized-betas/subj01'\n",
    "TRIAL_PER_SESS = 750\n",
    "# !pip install line_profiler\n",
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get the name of all files in the directory containgn the betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # returns a list of all files in the directory to be standardized\n",
    "def getDirFiles(FMRI_DIR):\n",
    "     files = [f for f in os.listdir(FMRI_DIR) if \n",
    "              os.path.isfile(os.path.join(FMRI_DIR, f)) and\n",
    "              f[-5:] == '.hdf5']\n",
    "     files.sort()                          \n",
    "     return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows each scan session is comprised of 750 scans. Each scan is of size (83, 104, 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas_session01.hdf5\n",
      "<KeysViewHDF5 ['betas']>\n",
      "(750, 83, 104, 81)\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "files = getDirFiles(FMRI_DIR)\n",
    "f = files[0]\n",
    "print(f)\n",
    "f = os.path.join(FMRI_DIR, f)\n",
    "scan1=[]\n",
    "with h5py.File(f, \"r\") as file:\n",
    "    print(file.keys())\n",
    "    print(file['betas'].shape)\n",
    "    scan1 = np.array(file['betas'])\n",
    "print(scan1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32767\n",
      "-32768\n",
      "-80.90666666666667\n",
      "-80.90666666666667\n"
     ]
    }
   ],
   "source": [
    "print(scan1.max())\n",
    "print(scan1.min())\n",
    "print(scan1.mean(0)[59,27,63])\n",
    "mean = np.mean(scan1,axis=0)\n",
    "print(mean[59,27,63])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "jtKW9A8gbRq9",
    "outputId": "cc67ec52-5d5f-4259-8c61-49cbc34d27ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering labels...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISCORRECT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27745</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27746</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27747</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27748</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27749</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17905 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       ISCORRECT\n",
       "45           1.0\n",
       "68           1.0\n",
       "90           1.0\n",
       "107          1.0\n",
       "121          1.0\n",
       "...          ...\n",
       "27745        1.0\n",
       "27746        1.0\n",
       "27747        0.0\n",
       "27748        1.0\n",
       "27749        1.0\n",
       "\n",
       "[17905 rows x 1 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('filtering labels...')\n",
    "res = pd.read_csv(LABLE_FILE, sep='\\t')\n",
    "res = pd.DataFrame(res)\n",
    "res = res.loc[res['SESSION'] <= 37]\n",
    "res = res.loc[res['ISOLD'] == 1]\n",
    "res = res.loc[res['ISCORRECT'] > -1]\n",
    "res = res.filter(items = ['ISCORRECT'] )\n",
    "res\n",
    "# for index, row in res.iterrows():\n",
    "#     print(index, row['ISCORRECT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HMZklVJzRXa"
   },
   "source": [
    "#Standardize all betas in the directory\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(FMRI_DIR_STND, FMRI_DIR_STND+\"/standardized_betas.hdf5\")\n",
    "new_betas = h5py.File(path, 'w')\n",
    "for index, row in res.iterrows():\n",
    "    print(index, row['ISCORRECT'])\n",
    "    \n",
    "new_betas.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O6lS_DPXzRB6"
   },
   "outputs": [],
   "source": [
    "class StandardizeDirectory:\n",
    "\n",
    "  def __init__(self, loading_dir, dumping_dir, response_file):\n",
    "    self.ld = loading_dir\n",
    "    self.dd = dumping_dir\n",
    "    self.rs = response_file\n",
    "    self.indx = 0\n",
    "    self.fmri_files = self.getDirFiles()\n",
    "    self.file_handlers ={}\n",
    "    self.open_files()\n",
    "\n",
    "  def __del__(self):\n",
    "    for value in self.file_handlers.items():\n",
    "      value.close()\n",
    "  # returns a list of all files in the directory to be standardized\n",
    "  def getDirFiles(self):\n",
    "     files = [f for f in os.listdir(self.ld) if \n",
    "              os.path.isfile(os.path.join(self.ld, f)) and\n",
    "              f[-5:] == '.hdf5']\n",
    "     files.sort()                          \n",
    "     return files               \n",
    "\n",
    "  def open_files(self): \n",
    "    for file_name in self.fmri_files:\n",
    "      path = os.path.join(FMRI_DIR, file_name)\n",
    "      self.file_handlers[file_name] = h5py.File(path, 'r')\n",
    "\n",
    "  # Input: path of the responses.tsv file\n",
    "  # Output: dictionary of indexes as keys with a corresponding class lable\n",
    "  # in put the sesh number to filter , pass the session as an argument \n",
    "  def get_labels(self):\n",
    "      print('filtering labels...')\n",
    "      res = pd.read_csv(self.rs, sep='\\t')\n",
    "      res = pd.DataFrame(res)\n",
    "      res = res.loc[res['SESSION'] <= 37]\n",
    "      res = res.loc[res['ISOLD'] == 1]\n",
    "      res = res.loc[res['ISCORRECT'] > -1]\n",
    "      res = res.filter(items = ['ISCORRECT'] )\n",
    "      return res\n",
    "\n",
    "  def dump(self):\n",
    "    path = os.path.join(self.dd, FMRI_DIR_STND+\"/standardized_betas.hdf5\")\n",
    "    new_betas = h5py.File(path, 'w')\n",
    "    new_betas.create_dataset()\n",
    "    for session in self.fmri_files:\n",
    "      partition = {} # ex: {'train': ['id-1', 'id-2', 'id-3'], 'validation': ['id-4']}\n",
    "      labels = {} # ex: {'id-1': 0, 'id-2': 1, 'id-3': 2, 'id-4': 1}\n",
    "      print('standardizing betas from '+ session)\n",
    "      sesh = np.array(self.file_handlers[session]['betas'])\n",
    "      mean = sesh.mean(0)\n",
    "      std = sesh.std(0)\n",
    "      standardized = (sesh-mean)/std\n",
    "      standardized.size\n",
    "      labels = self.get_labels()\n",
    "      for index, row in labels:\n",
    "        if index > self.indx:\n",
    "          break\n",
    "        new_betas\n",
    "\n",
    "      \n",
    "    \n",
    "      group_dict = {'betas':[],'labels':[] }\n",
    "      ready_data = self.standardize_data(sesh)\n",
    "      \n",
    "    \n",
    "      \n",
    "      \n",
    "    new_betas.close()     \n",
    "  \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TosxhDOOMZjW",
    "outputId": "16001725-9d2d-432c-a268-1667fd4501ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 1....\n",
      "DUMPED file 1\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 2....\n",
      "DUMPED file 2\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 3....\n",
      "DUMPED file 3\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 4....\n",
      "DUMPED file 4\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 5....\n",
      "DUMPED file 5\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 6....\n",
      "DUMPED file 6\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 7....\n",
      "DUMPED file 7\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 8....\n",
      "DUMPED file 8\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 9....\n",
      "DUMPED file 9\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 10....\n",
      "DUMPED file 10\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 11....\n",
      "DUMPED file 11\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 12....\n",
      "DUMPED file 12\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 13....\n",
      "DUMPED file 13\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 14....\n",
      "DUMPED file 14\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 15....\n",
      "DUMPED file 15\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 16....\n",
      "DUMPED file 16\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 17....\n",
      "DUMPED file 17\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 18....\n",
      "DUMPED file 18\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 19....\n",
      "DUMPED file 19\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 20....\n",
      "DUMPED file 20\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 21....\n",
      "DUMPED file 21\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 22....\n",
      "DUMPED file 22\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 23....\n",
      "DUMPED file 23\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 24....\n",
      "DUMPED file 24\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 25....\n",
      "DUMPED file 25\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 26....\n",
      "DUMPED file 26\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 27....\n",
      "DUMPED file 27\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 28....\n",
      "DUMPED file 28\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 29....\n",
      "DUMPED file 29\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 30....\n",
      "DUMPED file 30\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 31....\n",
      "DUMPED file 31\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 32....\n",
      "DUMPED file 32\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 33....\n",
      "DUMPED file 33\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 34....\n",
      "DUMPED file 34\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 35....\n",
      "DUMPED file 35\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 36....\n",
      "DUMPED file 36\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 37....\n",
      "DUMPED file 37\n"
     ]
    }
   ],
   "source": [
    "st = StandardizeDirectory(FMRI_DIR, FMRI_DIR_STND, LABLE_FILE)\n",
    "st.dump()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6H1EipqUJAYS",
    "hdrpCkvYmEIr"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
