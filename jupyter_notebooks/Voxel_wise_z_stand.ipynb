{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k64Z8hXNy-sh"
   },
   "source": [
    "#Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_iftfZn2Ndo",
    "outputId": "027459b3-252a-4ca7-f877-ed9a6d90b882"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "LABLE_FILE = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/ppdata/subj01/behav/responses.tsv'\n",
    "FMRI_DIR = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/GLM-fmri-data/subj01'\n",
    "FMRI_DIR_STND = 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/standardized-betas/subj01'\n",
    "TRIAL_PER_SESS = 750\n",
    "# !pip install line_profiler\n",
    "# %load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we get the name of all files in the directory containgn the betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "  # returns a list of all files in the directory to be standardized\n",
    "def getDirFiles(FMRI_DIR):\n",
    "     files = [f for f in os.listdir(FMRI_DIR) if \n",
    "              os.path.isfile(os.path.join(FMRI_DIR, f)) and\n",
    "              f[-5:] == '.hdf5']\n",
    "     files.sort()                          \n",
    "     return files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows each scan session is comprised of 750 scans. Each scan is of size (83, 104, 81)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "betas_session01.hdf5\n",
      "<KeysViewHDF5 ['betas']>\n",
      "(750, 83, 104, 81)\n",
      "750\n"
     ]
    }
   ],
   "source": [
    "files = getDirFiles(FMRI_DIR)\n",
    "f = files[0]\n",
    "print(f)\n",
    "f = os.path.join(FMRI_DIR, f)\n",
    "scan1=[]\n",
    "with h5py.File(f, \"r\") as file:\n",
    "    print(file.keys())\n",
    "    print(file['betas'].shape)\n",
    "    scan1 = np.array(file['betas'])\n",
    "print(scan1.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32767\n",
      "-32768\n",
      "-80.90666666666667\n",
      "-80.90666666666667\n"
     ]
    }
   ],
   "source": [
    "print(scan1.max())\n",
    "print(scan1.min())\n",
    "print(scan1.mean(0)[59,27,63])\n",
    "mean = np.mean(scan1,axis=0)\n",
    "print(mean[59,27,63])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 687
    },
    "id": "jtKW9A8gbRq9",
    "outputId": "cc67ec52-5d5f-4259-8c61-49cbc34d27ab"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtering labels...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/ppdata/subj01/behav/responses.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mfiltering labels...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m res \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(LABLE_FILE, sep\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m\\t\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      3\u001b[0m res \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(res)\n\u001b[0;32m      4\u001b[0m res \u001b[39m=\u001b[39m res\u001b[39m.\u001b[39mloc[res[\u001b[39m'\u001b[39m\u001b[39mSESSION\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m37\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\ezequ\\anaconda3\\envs\\NSD_CNN\\lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ezequ\\anaconda3\\envs\\NSD_CNN\\lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ezequ\\anaconda3\\envs\\NSD_CNN\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\ezequ\\anaconda3\\envs\\NSD_CNN\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\ezequ\\anaconda3\\envs\\NSD_CNN\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\ezequ\\anaconda3\\envs\\NSD_CNN\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\ezequ\\anaconda3\\envs\\NSD_CNN\\lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:/Users/007303173/Documents/Independent_Study_Project/nsd_data/ppdata/subj01/behav/responses.tsv'"
     ]
    }
   ],
   "source": [
    "print('filtering labels...')\n",
    "res = pd.read_csv(LABLE_FILE, sep='\\t')\n",
    "res = pd.DataFrame(res)\n",
    "res = res.loc[res['SESSION'] <= 37]\n",
    "res = res.loc[res['ISOLD'] == 1]\n",
    "res = res.loc[res['ISCORRECT'] > -1]\n",
    "res = res.filter(items = ['ISCORRECT'] )\n",
    "res\n",
    "# for index, row in res.iterrows():\n",
    "#     print(index, row['ISCORRECT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0HMZklVJzRXa"
   },
   "source": [
    "#Standardize all betas in the directory\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(FMRI_DIR_STND, FMRI_DIR_STND+\"/standardized_betas.hdf5\")\n",
    "new_betas = h5py.File(path, 'w')\n",
    "for index, row in res.iterrows():\n",
    "    print(index, row['ISCORRECT'])\n",
    "    \n",
    "new_betas.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "O6lS_DPXzRB6"
   },
   "outputs": [],
   "source": [
    "class StandardizeDirectory:\n",
    "\n",
    "  def __init__(self, loading_dir, dumping_dir, response_file):\n",
    "    self.ld = loading_dir\n",
    "    self.dd = dumping_dir\n",
    "    self.rs = response_file\n",
    "    self.index = 0\n",
    "    self.fmri_files = self.getDirFiles()\n",
    "    self.file_handlers ={}\n",
    "    self.open_files()\n",
    "\n",
    "  def __del__(self):\n",
    "    for value in self.file_handlers.items():\n",
    "      value.close()\n",
    "  # returns a list of all files in the directory to be standardized\n",
    "  def getDirFiles(self):\n",
    "     files = [f for f in os.listdir(self.ld) if \n",
    "              os.path.isfile(os.path.join(self.ld, f)) and\n",
    "              f[-5:] == '.hdf5']\n",
    "     files.sort()                          \n",
    "     return files               \n",
    "\n",
    "  def open_files(self): \n",
    "    for file_name in self.fmri_files:\n",
    "      path = os.path.join(FMRI_DIR, file_name)\n",
    "      self.file_handlers[file_name] = h5py.File(path, 'r')\n",
    "\n",
    "  # Input: path of the responses.tsv file\n",
    "  # Output: dictionary of indexes as keys with a corresponding class lable\n",
    "  # in put the sesh number to filter , pass the session as an argument \n",
    "  def get_labels(self):\n",
    "      print('filtering labels...')\n",
    "      res = pd.read_csv(self.rs, sep='\\t')\n",
    "      res = pd.DataFrame(res)\n",
    "      res = res.loc[res['SESSION'] <= 37]\n",
    "      res = res.loc[res['ISOLD'] == 1]\n",
    "      res = res.loc[res['ISCORRECT'] > -1]\n",
    "      res = res.filter(items = ['ISCORRECT'] )\n",
    "      image_index = []\n",
    "      labels = []\n",
    "      for index, row in res.iterrows():\n",
    "        image_index.append(index)\n",
    "        labels.append(row['ISCORRECT'])\n",
    "        print(index, row['ISCORRECT'])\n",
    "      return (image_index, labels)\n",
    "\n",
    "  def dump(self):\n",
    "    path = os.path.join(self.dd, FMRI_DIR_STND+\"/standardized_betas.hdf5\")\n",
    "    betas_file = h5py.File(path, 'w')\n",
    "    betas_ID, labels = self.get_labels\n",
    "    betas = []\n",
    "    betas_file.create_dataset(\"labels\", data = labels)\n",
    "\n",
    "    for session in self.file_handlers:\n",
    "      print('standardizing betas from session '+ session)\n",
    "      sesh = np.array(self.file_handlers[session]['betas'])\n",
    "      mean = sesh.mean(0)\n",
    "      std = sesh.std(0)\n",
    "      standardized = (sesh-mean)/std\n",
    "      for index in betas_ID:\n",
    "        if index >= self.index + TRIAL_PER_SESS:\n",
    "          self.index += TRIAL_PER_SESS\n",
    "          break\n",
    "        betas.append(standardized[index])\n",
    "    betas_file.create_dataset(\"betas\", data = betas)\n",
    "    betas_file.close()     \n",
    "  \n",
    "     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TosxhDOOMZjW",
    "outputId": "16001725-9d2d-432c-a268-1667fd4501ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 1....\n",
      "DUMPED file 1\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 2....\n",
      "DUMPED file 2\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 3....\n",
      "DUMPED file 3\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 4....\n",
      "DUMPED file 4\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 5....\n",
      "DUMPED file 5\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 6....\n",
      "DUMPED file 6\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 7....\n",
      "DUMPED file 7\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 8....\n",
      "DUMPED file 8\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 9....\n",
      "DUMPED file 9\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 10....\n",
      "DUMPED file 10\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 11....\n",
      "DUMPED file 11\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 12....\n",
      "DUMPED file 12\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 13....\n",
      "DUMPED file 13\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 14....\n",
      "DUMPED file 14\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 15....\n",
      "DUMPED file 15\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 16....\n",
      "DUMPED file 16\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 17....\n",
      "DUMPED file 17\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 18....\n",
      "DUMPED file 18\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 19....\n",
      "DUMPED file 19\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 20....\n",
      "DUMPED file 20\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 21....\n",
      "DUMPED file 21\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 22....\n",
      "DUMPED file 22\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 23....\n",
      "DUMPED file 23\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 24....\n",
      "DUMPED file 24\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 25....\n",
      "DUMPED file 25\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 26....\n",
      "DUMPED file 26\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 27....\n",
      "DUMPED file 27\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 28....\n",
      "DUMPED file 28\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 29....\n",
      "DUMPED file 29\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 30....\n",
      "DUMPED file 30\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 31....\n",
      "DUMPED file 31\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 32....\n",
      "DUMPED file 32\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 33....\n",
      "DUMPED file 33\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 34....\n",
      "DUMPED file 34\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 35....\n",
      "DUMPED file 35\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 36....\n",
      "DUMPED file 36\n",
      "begining dump\n",
      "filtering labels...\n",
      "...creating file 37....\n",
      "DUMPED file 37\n"
     ]
    }
   ],
   "source": [
    "st = StandardizeDirectory(FMRI_DIR, FMRI_DIR_STND, LABLE_FILE)\n",
    "st.dump()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "6H1EipqUJAYS",
    "hdrpCkvYmEIr"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "NSD_CNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d0eedda28e726887389b12365826c9a3c7088b0ff5b05732616b72a6f777d840"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
